# Core Script

```yaml
video_script:
  Content: "[]"
  prompt: 
    - "One page compatible with Elgato prompter"
    - "Text output use emojis"
    - "Expand or shrink for 100 words"
    - "Do not repeat the same words"
    - "Do not update [[]] for obsidian reference"
    - "For each slide rewrite and fix syntax for the prompter > target 100 words"
    - "Header formart L01-v1-[summarycontent]-tell-show "
    - "Example: #### **LO1-V4:START-GITHUB-ACTIONS-WITH-YAML-TELL-SHOW** âš™ï¸  
    - Format Template: 
      > use this format
      #### LO#-V##: TITLE WITH EMOJI / INCREMENT THE VIDEO NO
      [CONTEXT]
      [SHOW]
      [DO]
      [CLOSING]  
      No line breaks
```
####### todos
- remove tellshowdo from the script and beatboard index as integrated in all
- check the index at the top
- set the headers with lo lo2 lo3 intro promo with markdown
- fix the naming to v10 v31
- practice energy with hand printed notes
- show and do one liners
-  show and do new lines
- decide on how to give the details to the editors maybe the beatboard is enough and dont confuse the prompter

## Text Output >

### Practice Script 
#### LO1-V1: INTRODUCTION TO SONARQUBE ğŸš€  
[CONTEXT]  
Welcome to our **SonarQube** course! In todayâ€™s fast-paced world, delivering high-quality software isnâ€™t just about writing codeâ€”itâ€™s about **connecting the dots**, catching issues early, and keeping **technical debt** in check. With this course, youâ€™ll learn how to integrate your projects with SonarQube for **code analysis** and ensure **release readiness** throughout your **development lifecycle**. Most importantly, weâ€™ll adopt a **first-principles approach** to fixing issues effectively.  
[SHOW]  
SonarQube provides a comprehensive platform for analyzing code quality, identifying vulnerabilities, and managing technical debt. By integrating it into your workflow, you can ensure your software meets the highest standards of maintainability and security.  
[DO]  
In this course, youâ€™ll set up SonarQube, connect it to your projects, and perform hands-on exercises to analyze and fix code issues. Youâ€™ll also learn to interpret SonarQube reports and apply actionable insights to improve your codebase.  
[CLOSING]  
Letâ€™s get started and transform the way you approach software development! Together, weâ€™ll build the skills to deliver high-quality, maintainable, and scalable software. ğŸš€  

#### LO1-V2: OBJECTIVE ğŸ¯  
[CONTEXT]  
In this course, you'll gain hands-on experience with SonarQube, a powerful tool for managing code quality and technical debt. By the end, you'll understand how to integrate it into your development workflow and CI/CD pipelines.  
[SHOW]  
You'll learn to set up SonarQube in a development environment, integrate it with CI/CD pipelines, and analyze code quality and security vulnerabilities. This includes addressing infrastructure debt and improving your project's maintainability.  
[DO]  
Follow step-by-step instructions to configure SonarQube, connect it to your projects, and perform scans to identify and resolve issues. You'll also practice interpreting reports and applying fixes to enhance code quality.  
[CLOSING]  
By mastering these skills, you'll be equipped to tackle technical debt, improve software quality, and streamline your development process. Let's dive in and start building better software! ğŸš€  


#### LO1-V3: FLEXIBILITY IN SOFTWARE DEVELOPMENT ğŸŒ  
[CONTEXT]  
Hello, I'm Rifat Erdem Sahin. With over 40 successful IT contracts and 80 projects delivered globally, I've honed deep expertise in the software development life cycle. At Accenture, this pivotal tool enabled me to ensure code quality and maintainability across large-scale projects.  
[SHOW]  
Integrating SonarQube into CI/CD pipelines has streamlined continuous integration, supporting trunk-based development for rapid, reliable code releases.  
[DO]  
In this course, weâ€™ll explore how to integrate SonarQube into your workflows, ensuring maintainable, high-quality code for scalable projects.  
[CLOSING]  
In an ever-changing world, mastering these components will empower you to deliver impactful solutions. Letâ€™s dive in and make it work! ğŸŒŸ  
#### LO1-V3: REAL-WORLD EXPERIENCES AND LEARNING TO THRIVE IN TECH DEBT ğŸš€ğŸ”§  
[CONTEXT]  
In this course, weâ€™ll explore real-world challenges, focusing on navigating technical debt and achieving daily deployments. This isnâ€™t just theoryâ€”itâ€™s a hands-on journey into solving practical problems with tools like SonarQube.  
[SHOW]  
Iâ€™ll share personal experiences and strategies that have helped me tackle technical debt in real-world projects. From yak shaving to delivering scalable solutions, youâ€™ll gain insights into overcoming obstacles and building robust systems.  
[DO]  
Follow along as we set up SonarQube, resolve technical debt, and optimize workflows for continuous integration. Apply these lessons to your own projects, ensuring quality and scalability.  
[CLOSING]  
By the end of this course, youâ€™ll have the skills and confidence to tackle technical debt, deliver high-quality software, and thrive in real-world development environments. Letâ€™s get started! ğŸš€  

#### LO1-V4: BONUS: AI-FIRST PROJECT AND PORTFOLIO-READY SKILLS ğŸ¤–âœ¨  
[CONTEXT]  
This course includes a bonus AI-first project where youâ€™ll integrate AI tools to set up and optimize a SonarQube environment. Itâ€™s designed to sharpen your skills in AI-assisted development while ensuring top-tier quality standards.  
[SHOW]  
Youâ€™ll learn to use AI tools like Claude and GPT to iterate prompts, automate quality checks, and enhance your CI/CD pipeline. This hands-on project will prepare you for real-world applications of AI in software development.  
[DO]  
Build a fully functional SonarQube environment, integrate AI into your workflows, and apply these skills to improve code quality and manage technical debt. Document your progress to create a portfolio-ready project.  
[CLOSING]  
By the end, youâ€™ll not only master AI-assisted development but also have a showcase-worthy project to demonstrate your expertise. Letâ€™s innovate and build together! ğŸ¤–âœ¨  

#### LO1-V5: BUILDING A PORTFOLIO WITH SONARQUBE AND GITHUB ğŸŒŸ  
[CONTEXT]  
Creating a professional portfolio is essential for IT professionals, showcasing your ability to deliver high-quality, maintainable software. By integrating SonarQube into your GitHub projects, you demonstrate a commitment to code quality and technical debt management. This approach highlights your expertise in building scalable, customer-focused applications.  
[SHOW]  
SonarQube complements your GitHub portfolio by ensuring your code meets industry standards. It provides actionable insights into vulnerabilities, code smells, and maintainability, which are critical for delivering reliable software. Sharing these projects on LinkedIn and GitHub enhances your visibility and credibility as a developer.  
[DO]  
Explore the provided GitHub repository to access all the code and configurations used in this course. Use SonarQube to analyze your projects, document improvements, and share your results on LinkedIn. Highlight how SonarQube helped you address technical debt and deliver high-quality solutions.  
[CLOSING]  
By combining GitHub and SonarQube, you create a portfolio that not only showcases your technical skills but also your dedication to software excellence. Letâ€™s build a portfolio that stands out and opens doors to new opportunities! ğŸš€  
#### LO1-V6: WHAT IS SONARQUBE AND WHY DO WE NEED IT? ğŸ—ï¸  
[CONTEXT]  
SonarQube is an essential tool in modern software development. Think of software as a buildingâ€”it's not just about constructing it but maintaining its quality over time. In the Software Development Life Cycle (SDLC), technical debt accumulates as new requirements emerge. Managing this debt effectively is critical to ensure progress without compromising quality.  
[SHOW]  
SonarQube provides a structured process to measure, analyze, and reduce technical debt. It acts as a scale to track progress, ensuring your software remains maintainable and scalable.  
[DO]  
Use SonarQube to identify technical debt, integrate it into your SDLC, and prioritize fixes. Leverage its insights to allocate time effectively for addressing issues while meeting new requirements.  
[CLOSING]  
In todayâ€™s fast-paced world, AI accelerates change, making tools like SonarQube indispensable for maintaining high-quality, scalable software. Letâ€™s embrace it to build better systems! ğŸš€  

#### LO1-V7: BENEFITS OF SONARQUBE ğŸŒŸ  
[CONTEXT]  
SonarQube offers a comprehensive view of your code quality, helping you maintain high standards and improve your development process.  
[SHOW]  
It supports over 25 programming languages, fosters team collaboration, identifies technical debt, and integrates seamlessly into CI/CD pipelines for continuous quality checks.  
[DO]  
Integrate SonarQube into your workflow to monitor code quality, enhance team collaboration, and manage technical debt effectively. Use its CI/CD integration to automate checks with every commit.  
[CLOSING]  
By leveraging SonarQube, you ensure your codebase remains maintainable, scalable, and ready for future challenges. Letâ€™s make it a cornerstone of our development process! ğŸš€  

#### LO1-V8: SETTING UP YOUR ENVIRONMENT ğŸŒ  
[CONTEXT]  
Our initial objective is to set up the environment effectively. While production setups can be challenging, this course focuses on building a portfolio and presenting your ideas confidently. We will concentrate on Proof of Concept environments, leveraging infrastructure-as-code setups like Codespaces.  
[SHOW]  
For this course, I am using a Windows-based system but working within Codespaces. This approach demonstrates how to restore and fix SonarQube components using first principles.  
[DO]  
Choose your preferred environment, set up Codespaces, and follow the steps to configure SonarQube. Document your process to ensure you can rebuild and troubleshoot effectively.  
[CLOSING]  
By mastering these foundational skills and integrating AI-first implementations, youâ€™ll gain the confidence to handle any environment and showcase your expertise. Letâ€™s get started! ğŸš€  

##### LO1-v2-s2-shortcuts-tell-show
The ultimate shortcut is to use a [4.18.1_cloud_implementations.png](cloud-based rental system) for SonarQube. This eliminates the need for setup, allowing you to quickly start scanning projects. While this approach is convenient, itâ€™s crucial to understand the deployment components, as SonarQube is often used in enterprise environments. Learning these fundamentals ensures a first-principles approach, enabling you to adapt to various project requirements. Weâ€™re focusing on this method not because itâ€™s easy, but because mastering the setup process builds a deeper understanding. This knowledge is invaluable, especially when working with dynamic environments like Codespaces, which can be ephemeral by nature.

##### LO1-v2-s3-infradebt-tell-show  
SonarQube is a tool for managing technical debt, a critical yet often overlooked concept in IT. Technical debt refers to the compromises made in infrastructure or code that may lead to future challenges. In this course, we rely on GitHub Codespaces to host processes for running SonarQube. While the free tier contract(debt) offers a limited timeline, it introduces potential trade-offs, such as resource shutdowns. Students should focus on understanding these trade-offs and learning how to restore components when needed. [4.19.1_codespacescost2025April.png](For basic usage in this course,) the free tier suffices, but exceeding limits may incur additional costs. Manage resources wisely!

##### LO1-v2-SettingUpEnvironment-tell  
For most students, accessing the environment requires virtualization. Setting up the environment is our primary goal and a critical task. We should approach it in a way that allows us to rebuild it with ease. This is about becoming skilled, and I wasnâ€™t always in that position. Initially, I looked for shortcuts, but Iâ€™ve come to realize that this is one of the harder yet more meaningful ways to build it.  
The system we are building will face challenges staying online, but these challenges will provide valuable learning opportunities. My proof-of-concept choice is Linux and a cloud-based solution called Codespaces, which has a strong community behind it.  
As a side note, this might feel like a bit of "yak shaving," but this Kubernetes and cloud-based vision will pay off for IT professionals in the long run. Trust me, I was once skeptical of this approach, but it has proven to be invaluable.

##### LO1:v3:linuxBased-Show-Do
Our pick is GitHub Codespaces. First, create your GitHub account, repository, and Codespaces environment on the GitHub platform. Our goal is to access the Minikube resource, which has already been deployed there. The free account provides temporary access to run the `minikube start` command. 
There are no excuses, such as not having access to a machine or being unable to open a GitHub repository. Codespaces offers a portfolio-ready environment for IT professionals, including tools like GitHub Actions. 
Please open the terminal, run the command, and watch Minikube go online. Once it's running, we can proceed to install the SonarQube platform on it.

##### LO1-v3-Codespeaces-Terminal-Getting-UsedTo-Tell-show
When you're inside Codespaces with Minikube, youâ€™re operating through multiple layersâ€”your machine, the Codespaces host, then Minikube. Each level has its own role. Some commands must target the Minikube agent specificallyâ€”especially when [4.4_max_heap_count_settings.png](configuring) host-level settings. Keep in mind, you're interacting with: the host, Codespaces, Minikube, container runners, SonarQube, and finally the scanner. Understanding this stack is key to troubleshooting and setup. In SDLC that is going to be your main challange understand the integration and how the code flows to pay the techical debt.

##### LO1-v3-LearnToDeployInEnvironment-Show-Do
SonarQube is a multi-tier systemâ€”UI, backend logic, and a database.  Youâ€™ll deploy it into a new environment using **Minikube**, a local Kubernetes cluster configured to run multiple (components)[4.5_rolloutstart.md] . Kubernetes helps you manage and observe all parts of your deployment.  Letâ€™s learn to deploy, inspect resources, and understand how everything fits together.Pod,Service,Deployment and Replica sets are internal component for the kubernetes to be able to run the processes. This course is not a kubernetes course. Still these are important concepts in the long run to learn in order to maintain the SonarQube in a containersed enterprise environment. 

##### LO4-V4:SETUP-ADMIN-PASSWORD-TELL-SHOW 
After launching SonarQube in Minikube, both the UI and database layers are active. The UI will prompt you to log in using the default credentials: admin/admin. Once logged in, you must reset the admin password. This new password is stored in the configuration database inside your Minikube environment. This step finalizes the initial setup and secures your SonarQube instance. As long as your Codespaces environment remains active, this password will persist. This process also confirms that the UI is correctly communicating with the backend and database, ensuring the system is ready to handle code scans and analysis tasks.


##### LO1-V4:SETUP-REPO-ENVIRONMENT-FIRST-PROJECT-TELL-SHOW
Set up the repository and environment to prepare for your first project. Our goal is to scan code automatically using SonarQube running in Minikube inside Codespaces. The code lives in the [4.8_GITHUB.PNG](GitHub repository) â€” thatâ€™s what weâ€™ll scan. The environment and the code are separate: we maintain the repo and the scanner seperately, not the same thing. Codespaces, which includes Minikube and SonarQube, will pull the repo and run a scan on every commit. â€” Watch how the repository in Github actions with our agent in the following steps [XXX](connects).

##### LO1-V4:GITHUB-SETUP-TELL-SHOW
The GitHub setup is critical to get all systems working in the background. Youâ€™ll need to authorize access and create both an App ID and a [SHOW](Client ID). These credentials are essential for integration and automationâ€”especially for connecting your repo to SonarQube scans. Take notes and store these values securely. Codespaces environments can be [DO]rebuilt or shut down at any time, so keeping track ensures you can recover and restart everything quickly.

**LO1-V4:GITHUB-APP-CONNECTOR-TELL-SHOW**  
For GitHub integration, weâ€™re using GitHub App connectors to allow apps to interact securely with your environment. Youâ€™ll need to [SHOW]grant access and manage the connection properly. As mentioned earlier, itâ€™s crucial to store your configuration detailsâ€”like App ID, Client ID, and secretsâ€”safely. Use systems like LastPass or a secured text file on a trusted cloud provider to hold your security notes. [DO]Connect the GitHub App to your environment to enable automated scans and background operations. This setup ensures consistent access and control, even if Codespaces is restarted or rebuilt.

**LO1-V4:GITHUB-KEY-GENERATION-TELL-SHOW**  
We are going to generate the keys needed to secure the GitHub environment. Your **Developer Settings** in GitHub will be the main area where this happens. In your GitHub application, youâ€™ll [SHOW]generate and manage these keys, including the private key and webhook secret. All of these should be placed into the same [DO]configuration file you use for the App ID and Client ID. Keeping everything together ensures the system can be easily restored or reused when rebuilding Codespaces. This step is essential for maintaining a secure and functional integration between GitHub and your SonarQube environment.

**LO1-V4:PRIVATE-KEY-PAM-FILE-TELL-SHOW**  
One of the key files youâ€™ll generate is the **.pem** (Privacy Enhanced Mail) file for your private key. This file is sensitive and should **never** be committed to source control. [DO]Use a `.gitignore` file to exclude it from your repo. The `.pem` file can be large and may create a cacheâ€”so youâ€™ll want to handle it carefully.  
Store this file securely in a configuration system like **LastPass**, **1Password**, or a trusted cloud storage service. [SHOW]Learn how to open and read this file using tools like `cat` or a text editor, so you can validate or migrate it when needed.

## **LO1-V4:PEM-FILE-HANDLING-TELL-SHOW**  
To manipulate `.pem` files, you can use **Notepad** or any text editor to view the content. [SHOW]Look for the markers:  
`-----BEGIN RSA PRIVATE KEY-----`  
`-----END RSA PRIVATE KEY-----`  
Make sure to **copy the entire content**, including the headers and footers. [DO]Paste it into a secure location like LastPass or your configuration vault. The private key works **together** with the public keyâ€”so you need to store **both**. If you only save the private key, remember the public key may already be on the server. Keeping both ensures you can rebuild or reauthenticate without issues.

#### **LO1-V4:GITHUB-WEBHOOK-CONFIG-TELL-SHOW** ğŸ”—  
Youâ€™ll set up a **webhook** so GitHub can notify your systems whenever changes occur in your repo. Your code lives in GitHubâ€”either as a public open-source repo or a private one. Itâ€™s a central and secure place to manage your code. [SHOW] SonarQube provides a **webhook URL** that tells the agent where to send scan events.  
[DO] One agent can send events to multiple URLs, so itâ€™s your job to configure it properly. ğŸ¯ Assign the correct webhook to your project so events flow to the right place, enabling automated scans and CI workflows. âš™ï¸

#### **LO1-V4:ENVIRONMENT-COMPONENTS-TELL-SHOW** ğŸ§©  
To understand the full setup, break down the key components: your **Dev environment** (the browser + GitHub Codespaces), where youâ€™ll enter and start building. Inside Codespaces, youâ€™ll run **Minikube** and install YAML templates to deploy **SonarQube**.  
[SHOW](4.9.7) SonarQube will connect to your **GitHub repo** using **webhooks**, and trigger **GitHub Actions** for CI events.  
[DO](4.9.7.B) All these componentsâ€”Dev tools, Minikube, SonarQube, GitHub, webhooks, and actionsâ€”must work together continuously. ğŸ” This integration helps track and resolve issues at every step, making sure your codebase is always being scanned and improved. âœ… By paying the technical debt

#### **LO1-V4:GITHUB-APP-PERMISSIONS-TELL-SHOW** ğŸ”  
When integrating your app with GitHub, youâ€™ll define **access levels and permissions** across your repos. With 100+ repos and 100+ permission types, itâ€™s important to manage access efficiently. [SHOW](4.9.8) In an enterprise environment, access is usually assigned **repo by repo**, specifying if the app can merge PRs, read code, or write to branches.  
[DO] For training or quick setup, you can assign permissions in **bulk**. If you're unsure, give access temporarilyâ€”then **delete the app** when you're done. âš ï¸ Always consider security. Granting only what's needed reduces risks and helps you manage trusted integrations responsibly. ğŸ›¡ï¸

#### **LO1-V4:SELECT-REPO-AND-DEPLOY-TELL-SHOW** ğŸ—‚ï¸  
Select your **GitHub repo** and [SHOW] **dismiss the top update message**â€”it can lead to unnecessary distractions or "yak shaving" ğŸƒ. Weâ€™re using a **YAML structure** to deploy SonarQube, which makes version updates simple and repeatable.  
[DO] The CI system will use the repo you choose on this screen to trigger scans. Iâ€™ve selected our existing **SonarQube repo**, and thatâ€™s perfectly fine. Once scanning starts, any issues will be shown in the results panel and you'll get notifications to address them. âœ… Keep things clean, focused, and version-controlled.

#### **LO1-V4:SETUP-SCANNING-AGENT-TELL-SHOW** ğŸ¤–  
To scan your project, youâ€™ll need an **agent**â€”in our case, that's **GitHub Actions**, which runs directly inside GitHub. [SHOW] Since your repo is already on GitHub, the agent can easily find and scan itâ€”location matters here. Keeping everything inside GitHub simplifies access and reduces setup friction.  
[DO] For this **proof of concept**, weâ€™re skipping complex security layers and network restrictions. ğŸ§ª The goal is to scan your code easily, test the setup, and allow controlled failures. In a **production setup**, youâ€™d add multiple security zones, but for now, speed and simplicity are key. ğŸš€

#### **LO1-V4:PROJECT-SCANNING-TRIGGERS-TELL-SHOW** ğŸ”„  
Set up your project for scanning, and make sure your **CI system works side-by-side** with SonarQube. [SHOW] Itâ€™s not enough to just link the projectâ€”you need to create **automated triggers**. These can fire on every commit, on a daily or weekly schedule, or based on specific conditions.  
[DO] These scans will automatically analyze your code and notify **stakeholders** via email, Slack, or Teams. ğŸ“¬ Once this system is in place, it becomes part of your workflow. You'll start receiving regular reports from the agent, making continuous analysis a seamless part of your development life. ğŸ› ï¸

#### **LO2-V4:START-GITHUB-ACTIONS-WITH-YAML-TELL-SHOW** âš™ï¸  
To get GitHub Actions running, start with a **simple YAML workflow**. [SHOW] YAML (Yet Another Markup Language) is the backbone of most modern platform configurationsâ€”essential for defining CI/CD pipelines, infrastructure, and deployment rules.  
[DO] I recommend using **GPT to help generate or review** your YAML files. In this repo, all prompts and examples are GPT-assisted. Ask it to explain or **add comments** if anything feels unclear. This makes your workflows not just functional, but understandable. YAML is your **config language for infra**, so mastering it will pay off across platforms. ğŸ§ ğŸ“

#### **LO2-V4:COMMIT-TIMING-AND-QUALITY-ANALYSIS-TELL-SHOW** â±ï¸  
Understanding **commit timing** is crucial when working with Git repositories. Since you're using **Codespaces**, Git is already installed, and you're working with a browser-based IDE. [SHOW] Each commit is like a **cell division in your system's DNA**â€”whenever you change code, it gets replicated.  
[DO] It's essential to **pay down technical debt** with each commit. SonarQube will automatically analyze each commit and flag any **quality issues**. ğŸš¨ The trigger for this analysis is vital: it ensures that as soon as a commit happens, potential problems are identified early, helping you maintain high-quality, clean code. ğŸ§‘â€ğŸ’»


#### **LO2-V4:HANDS-ON-SONARQUBE-DEPLOYMENT-TELL-SHOW** ğŸ› ï¸  
In this **hands-on experience**, you'll create your own **GitHub environment**. Start by creating a GitHub account and a new repository. You can either **fork** my repo or **start from scratch**. [SHOW] Ensure that you complete all sign-up steps to get your environment set up.  
[DO] The **free-tier Codespaces** should work fine for this project, but if you want to keep your system from shutting down, consider upgrading. Your main goal is to **deploy a SonarQube cluster** within a **Minikube** environment. Minikube is a small, local Kubernetes cluster that will let you see the **SonarQube UI** running directly within your setup. This step is crucial to see SonarQube in action and interact with the analysis process! ğŸš€

#### **L02-In-Video Question** ğŸ¥
What do you think about the environments we've set up for this section? Do you feel comfortable using **Codespaces** and a **browser-based approach**? Is your **internet connection stable** enough to handle this setup? Are you planning to use **Mac** or **Windows** for this project? Do you feel confident following the **AI-driven setup** process? Lastly, have you explored the **SonarQube environment**? Everything weâ€™ve covered should be replicable on your end. Remember to check the **GitHub repo** where Iâ€™ve recorded every step. You should be able to reverse engineer the setup by reviewing the repository. 
Please answer all of these questions to reflect on your progress! ğŸ˜Š

#### **LO1-V4:YAML-CONNECTS-SYSTEM-TELL-SHOW**  
YAML plays a crucial role in connecting various parts of the system. In the SonarQube ecosystem, you'll see the use of multiple layers of Linux environments. Initially, you're working within a **Linux inside another Linux** to trigger processes. Here's how it works:  
1. **Checkout the code**: The first step is to pull the repository code.  
2. **Scan the repository**: Once the code is checked out, the scan process begins.  
3. **Key components**: To run the scan, two essential pieces are required:
   - **Token**: For authentication.
   - **Host URL**: To connect to the scanning service.  
4. **GitHub Actions**: These actions are set to first check out the code and then trigger the scan with SonarQube.  
This setup allows the **GitHub Actions** to understand that after the code is checked out, it will automatically run the scan and execute the necessary build processes accordingly.

#### **LO1-V4:ENVIRONMENT-VARIABLES-TELL-SHOW**  
When working on remote systems, **environment variables** are your best friend ğŸ–¥ï¸. They are crucial in any systemâ€”Linux ğŸ§, DOS, or macOS ğŸ. To get the most out of your environment, **load these variables** ğŸ› ï¸. If you're using GitHub Codespaces, youâ€™ll directly interact with these environment variables.  
To familiarize yourself with them:  
- Use the **terminal** ğŸ–¥ï¸ (Mac Terminal, Windows PowerShell).
- Use **GPT** ğŸ’¬ to understand the concept of environment variables and how they function in your setup.  
These variables are key to configuring the system properly âš™ï¸. If you can't set them correctly, the system won't be able to run your jobs for SonarQube.

#### **LO1-V5:ENVIRONMENT-VARIABLES-POWER-AND-USAGE-TELL-SHOW** ğŸŒ
Working on remote systems? Environment variables will be your best friend. [SHOW] These variables are used across Windows (PowerShell), macOS (Terminal), and Linux systems to pass configuration values like tokens, URLs, and secret keys into your runtime environments. They are also essential in CI/CD systems like GitHub Codespaces or GitHub Actions.
[DO] Try setting them in your local terminal to get hands-on practice:
In PowerShell:
powershell
Copy code
$env:MY_VARIABLE = "my_value"
echo $env:MY_VARIABLE
In macOS/Linux:
bash
Copy code
export MY_VARIABLE="my_value"
echo $MY_VARIABLE
Use GPT to explain any part of this you donâ€™t fully getâ€”ask it â€œWhat is an environment variable?â€ or â€œWhy use these in CI/CD?â€ ğŸ§ ğŸ” Mastering this will help you securely configure systems without hardcoding values into your code.

#### LO1-V6:TRIGGER-SCAN-AFTER-COMMIT-TELL-SHOW ğŸ”
Every commit triggers a scan process via GitHub Actions. [SHOW] Youâ€™ll see this in your repoâ€™s Actions tabâ€”each workflow run shows live status like âœ… success or âŒ fail, helping you trace issues quickly.
[DO] Expect friendly fails at the beginning! Thatâ€™s normal. SonarQube checks your code for technical debt, and itâ€™ll highlight issues automatically. Your job is to identify the root cause and apply improvements. Donâ€™t rush to pass everything; instead, define a reasonable quality gateâ€”code should meet basic standards without blocking all progress. Learn to strike a balance between quality enforcement and dev speed. ğŸš¦ğŸ› ï¸

#### LO1-V8:UNDERSTAND-COSTS-OF-AGENTS-TELL-SHOW ğŸ’¸
When running GitHub Actions or using CodeSpaces, it's important to understand what youâ€™re actually paying for. [SHOW] In this setup, the agent (GitHub Actions) is serverless, meaning you donâ€™t own or run a full-time serverâ€”it spins up on demand, does the job, and shuts down. Thatâ€™s why the cost is low: around $4/month for V40s agents and associated CodeSpaces.
[DO] Think of it like renting a car ğŸš—â€”you only pay when you drive. Serverless infrastructure is cost-efficient when you donâ€™t need 24/7 uptime. Instead of paying to keep a host always on, GitHub gives you shared infra, which is perfect for CI/CD jobs that run for short bursts. Use this model wisely to optimize your spending while getting powerful compute on demand. ğŸ§®ğŸ“Š

#### **LO1-V9:ENHANCE-CODE-SHARING-WITH-IDES-TELL-SHOW** ğŸ§‘â€ğŸ’»ğŸ”—  
Working with GitHub commits is easier when using a **desktop IDE** like **Visual Studio** or **VS Code**. [SHOW] These tools offer powerful features and **extensions**â€”and you can even use them **inside GitHub CodeSpaces**. One essential extension is **"Copy GitHub URL"**, which lets you right-click any file or line and get a direct link to share with your team.
[DO] Whether in CodeSpaces or on your **local machine**, make sure to install helpful extensions that **sync across devices** using your Microsoft account. When SonarQube flags issues, youâ€™ll need to **share specific file locations** easily. Use these tools to collaborate faster, debug smarter, and level up your dev setup. ğŸš€ğŸ§©

#### **LO1-V10:SHARE-SONARQUBE-INSIGHTS-WITH-YOUR-TEAM-TELL-SHOW** ğŸ¤ğŸ”  
As mentioned earlier, the main goal of using **SonarQube** is to **pay down technical debt**. [SHOW] You're operating in an **open-source mindset**â€”this means actively **sharing URLs**, reviewing feedback, and collaborating with teammates to improve code quality.
[DO] Donâ€™t isolate yourselfâ€”**avoid working in silos**. Use features like **â€œCopy GitHub URLâ€** or **SonarQube report links** to initiate conversations. Drop those links into Slack, Teams, or pull request comments. Make it a habit to **discuss code issues openly**, and **learn from your teamâ€™s perspective**. SonarQube isnâ€™t just about finding problemsâ€”itâ€™s a **learning experience** that gets better the more you collaborate. ğŸŒ±ğŸ“

#### **LO1-V11:USE-URLS-MARKDOWNS-AND-INDEXES-TO-COMMUNICATE-CODE-TELL-SHOW** ğŸ”—ğŸ—‚ï¸  
When working in **GitHub Codespaces**, youâ€™ll notice that **sharing URLs**, **committing clearly**, and **naming resources** becomes a critical part of your workflow. [SHOW] This is a browser-based IDE, but the same concepts apply across environmentsâ€”**indexing your folders**, using meaningful names like `048-UI`, and **organizing with Markdown** all help make your system more readable.
[DO] Use GPT to help maintain structure and clarity. Maintain a personal index structure and be consistent. Markdown is your **visual communicator**â€”make sure your READMEs, documentation, and code comments are easy to follow. As you introduce concepts like **technical debt**, your job will also be to **explain it well to non-technical stakeholders**. Communicating is codingâ€”**index smart, document clear, and share responsibly**. ğŸ“šğŸ’¬

#### **LO1-V12:VISUALIZE-TECHNICAL-DEBT-WITH-EXTENSIONS-TELL-SHOW** ğŸ§©ğŸ“Š  
Using **extensions for SonarQube, YAML, and Markdown** takes your coding experience beyond textâ€”it becomes **a visual game** where managing **technical debt** feels structured and clear. [SHOW] With IDE plugins and GitHub integrations, youâ€™ll start to **see issues before they grow**, understand error highlights, and grasp complexity via visuals.
[DO] Install key extensions in **Codespaces or local VS Code**, including SonarQube support, Markdown preview, and YAML validators. These make it easier to **spot issues, explain problems, and collaborate**. Leverage **GPT to help comment, structure, and write your Markdown**, especially when documenting technical decisions. Your goal? **No more cryptic folders or hidden logic**. Every file should be understandableâ€”even if you come back to it months later. ğŸ› ï¸ğŸ“‚

#### **LO1-V13:SHOWCASE-SONARQUBE-IN-YOUR-CAREER-TELL-SHOW** ğŸ¯ğŸ’¼  
As an instructor or developer, **making your work visual and measurable boosts both credibility and career growth**. [SHOW] SonarQube isnâ€™t just a toolâ€”itâ€™s a **career asset**. Mentioning it in your **CV, LinkedIn, and GitHub projects** shows you care about clean code and scalable systems.
[DO] If you're using SonarQube in projectsâ€”especially in tools like your **Delivery Pilot**â€”**document it clearly**. Share your learnings, screenshots, and metrics. Mention how it helped you **reduce technical debt** and improve code quality. Add it as a skill on LinkedIn and explain your usage in project descriptions. Recruiters and teams value professionals who don't just write code, but improve its health and maintainability. ğŸ› ï¸ğŸš€

#### **LO1-V14:USE-SONARQUBE-AS-A-CREDIT-SCORE-TELL-SHOW** ğŸ“ŠğŸŒ  
In the future, your **technical debt score** will be just as important as your credit score. [SHOW] LinkedIn and other professional platforms are already asking for **GitHub URLs** on project listings, and **SonarQube** is key to demonstrating the **quality** of your code. It's no longer enough to show *just* your projectsâ€”you need to show **quality projects**. SonarQube helps you do that by tracking **technical debt** and offering insights on how to improve.
[DO] Treat your GitHub as your **digital portfolio**, and SonarQube as your **proof of quality**. By actively monitoring and improving your code quality, you'll signal to future employers or collaborators that youâ€™re serious about **software craftsmanship**. **Open-source contributions** are great, but **well-maintained, high-quality contributions** will make your profile stand out even more. **AI systems** and **recruiters** alike will take notice of your work. ğŸ“šğŸ’¼
And if you need guidance on this concept, there's a book called **"Show Your Work"** by Austin Kleon that perfectly aligns with this idea. Itâ€™s all about making your work visible and building your personal brand as a developer. ğŸŒŸ

#### **LO1-V15:INTEGRATE-SONARQUBE-INTO-YOUR-PROJECTS-TELL-SHOW** ğŸ“ˆğŸ”—  
When you work with **SonarQube**, you're not just improving code qualityâ€”you're also building a **digital history**. [SHOW] By tracking and committing your work on **GitHub** and integrating **SonarQube** into your projects, you create a clear trail of your progress. This helps you document every stage of your development process, from **initial integration** to resolving technical debt and improving code quality.
[DO] **Make sure to mention SonarQube in your projects**, both on GitHub and on platforms like **LinkedIn**. This not only showcases your technical ability but also highlights that youâ€™re committed to maintaining **enterprise-level quality**. It demonstrates to recruiters or collaborators that you're actively working on **scalable, high-quality solutions**â€”something that stands out in the competitive tech world. ğŸ”ğŸ’¡
Your **GitHub history** becomes your **proof** of expertise, and **SonarQube** acts as a tool that documents and improves that expertise. When you explain your projects, share how **SonarQube** helped you reach **quality gates**, address technical debt, and ensure sustainable development. **Let others see how youâ€™re growing**, and make your work visible to the broader tech community. ğŸŒğŸ‘©â€ğŸ’»ğŸ‘¨â€ğŸ’»

#### **LO1-V16:INTEGRATE-SONARQUBE-INTO-DAY-TO-DAY-DEVELOPMENT-TELL-SHOW** ğŸ”„ğŸ”  
As you work on your projects, youâ€™re not just codingâ€”youâ€™re **actively managing and improving** your **technical debt**. [SHOW] By integrating **SonarQube** into your **development lifecycle**, you ensure that every piece of code is consistently **scanned for quality**. The **GitHub history** becomes a **living record** of your work, capturing every update, every fix, and every improvement to your code.  
[DO] Treat **SonarQube** as part of your **daily development process**. **Clean up technical debt every day**, whether itâ€™s a small change or a major update. The more **SonarQube scans** you complete, the **higher the quality** of your software development lifecycle becomes. This consistent process shows **progress** in real time, proving your commitment to **quality code**.
Use **Markdowns**, **visual tools**, and **structured indexing** to make your **SonarQube results** clearer and more actionable. This not only makes it easier to understand the issues but also allows you to **track improvements over time**. The more you update your code with **SonarQubeâ€™s recommendations**, the stronger your **developer portfolio** becomes. Keep showing your work, keep improving, and stay ahead of technical debt! ğŸ“ˆğŸ’».

#### **LO1-V17:RECONNECT-AND-PAY-OFF-TECHNICAL-DEBT-TELL-SHOW** ğŸ”„ğŸ’³  
Think of **technical debt** as a **contract**â€”just like using a credit card for purchases, there's an ongoing responsibility to **pay off the debt**. [SHOW] If you stop paying, systems like **SonarQube**, **infrastructure**, and **code repositories** may shut down, and everything you've worked on will stop functioning. When you stop the system, you lose all progress unless you **reinitialize** the process.  
[DO] Always be ready to **pay off your technical debt** and **reconnect** the necessary components when they stop. This includes **reinitializing your setup**, such as the **mini Cube** or **GitHub Actions**, and following the steps outlined in the **underscore input** directory (located in the `second_minikube folder). Understand that each time you iterate, you need to **keep the debt paid off**â€”or else, your **development cycle** might grind to a halt.
Itâ€™s a simple but critical process: if you stop paying for the infrastructure, it **shuts down**. The key is knowing how to **reconnect** and keep everything running smoothly, ensuring that your **technical debt** doesnâ€™t prevent progress. ğŸš§âš™ï¸

#### **LO1-V18:SET-ENVIRONMENT-AND-RUBBER-DUCK-THE-PROCESS-TELL-SHOW** ğŸ§µğŸ§   
Open your terminal and navigate to the folder with `input.md`. [SHOW] This is where you'll set environment variables and run commands.  
[DO] Donâ€™t run everything blindlyâ€”**select and understand** each line. Use **Copilot** or **GPT** to comment and clarify. Structure your folders smartlyâ€”like `formulas/` for rules, errors, and references.  
This setup helps you "rubber duck" your processâ€”reviewing step by step makes debugging easier. Document as you go, and youâ€™ll build a self-healing workspace thatâ€™s ready for SonarQube and future iterations. ğŸ§°ğŸ’¬

#### **LO1-V19:RUBBER-DUCK-WITH-AI-AND-LOCK-STAGES-TELL-SHOW** ğŸ§ ğŸ§ª  
Lock your progress at **each stage**â€”P.O.C., prototype, production. [SHOW] This keeps your commits meaningful and traceable in complex systems like SonarQube.  
[DO] Rubber ducking means explaining your process, even to yourselfâ€”or in this case, the AI. Use **Copilot** or **GPT** to annotate changes and clarify decisions. Track evolving requirements and environment shifts between stages.  
Let your AI pair-program with you. The clearer your data and structure, the better the AI can help you manage complexity, debug issues, and ensure quality in every step. ğŸ¤ğŸ’»

#### **LO1-V20:SET-BREADCRUMBS-FOR-AI-NAVIGATION-TELL-SHOW** ğŸ§­ğŸ—‚ï¸  
Focus on **one document at a time**, but design your folder and file structure so the **AI can understand the full context**. [SHOW] In my `delivery_pilot` project, every task, prompt, and result is logged in the correct folderâ€”nothing is scattered.  
[DO] Create breadcrumb trails by saving prompt logs and outputs. This way, when something fails or needs debugging, you (or the AI) can retrace steps and find root causes. A clear structure + prompt history = **AI that truly helps**. Start small, stay consistent, and **log as you go**. ğŸ§±ğŸ¤–

#### **LO1-V21:STAY-NEUTRAL-AND-OPEN-TO-LEARN-TELL-SHOW** ğŸ§ ğŸŒ€  
Paying down tech debt frees your focusâ€”**less clutter, clearer goals**. [SHOW] Working in CodeSpaces? Expect hiccups, but donâ€™t get attached to a fixed setup. Stay flexible, restart when needed, and use GPT to help you learn.
[DO] Static analysis like SonarQube runs deepâ€”multiple rules, interwoven checks. Youâ€™ll need curiosity to understand how everything fits together. Drop blockers like â€œI wonâ€™t touch Docker.â€ That mindset stalls growth. Embrace the unknown, and **learning gets easier**. ğŸŒ±ğŸ§©

#### **LO1-V22:RECREATE-INFRASTRUCTURE-AS-YOU-LEARN ğŸ”âš™ï¸**  
Fixing systems *is* learning. [SHOW] When using GitHub Codespaces, expect them to expire if left idleâ€”Microsoft wonâ€™t cover infinite compute. Your infra setup (scripts, Kubernetes configs) will vanish unless you stay active.
[DO] Accept this impermanence. Practice recreating from `input.md` and document your process. The goal isn't one-time setupâ€”it's mastering rebuilds. Let GPT guide your repetition. Life interrupts, and thatâ€™s okay. Donâ€™t rush. Understand the system architecture and iterate calmly. The more you rebuild, the more you own your stack. ğŸ› ï¸ğŸ§˜â€â™€ï¸

#### **LO1-V23:UPDATE-SCRIPTS-BRAVELY ğŸ”„ğŸ“œ**  
Scripts are not staticâ€”*everything evolves.* [SHOW] GitHub Actions, Codespaces, and Kubernetes versions shift. Your configs must adapt too.
[DO] Go to your `scripts/` folder often. When things break, *donâ€™t panic*â€”edit the scripts, reconfigure, and re-run. The desired state is never guaranteed, itâ€™s *maintained*. Build the habit of refining your scripts instead of fearing failure. Courage to tweak and test is key. Every update is a chance to learn. ğŸ§ ğŸ’ª

#### **LO1-V24:RECONFIGURE-SECRETS & ASK GPT ğŸ”ğŸ¤–**  
Secrets like DB passwords are **not persistent**â€”they vanish with each reset. You must **redefine them** manually or through automation every time.
[DO] Revisit your configuration scripts. Identify connection points (e.g., DB URIs, tokens). Talk to GPT clearly:  
ğŸ—£ï¸ _"Search my codebase. What config am I missing to bring SonarQube back up?"_  
Use AI like a team memberâ€”debug with it, ask it to validate each step, and help you fill the gaps. Thatâ€™s how you stay in control when infra resets.

#### **LO1-V25: PODS, SERVICES, DEPLOYMENTS, REPLICAS ğŸš€**  
In Kubernetes:
- **Pods** = The processes running your applications. Think of them as the execution units.
- **Services** = Defines how these pods communicate within the cluster, either through a **ClusterIP** or **NodePort**.
- **Deployments** = Configuration that defines how your app is **deployed**, how it should scale, and the number of replicas.
- **ReplicaSets** = Ensures your specified number of pods (replicas) are always running. A **higher replica count** means **more memory usage**.  
In your **Minikube**, use **one replica** for simplicity and resource-saving. More replicas mean more resources, so be mindful when scaling.

#### **LO1-V26: PORTSAND RUNNINGSYSTEMğŸš€
When the system is up and running, hereâ€™s what youâ€™ll see:
1. **Pods** are the active processes that are running the application.
2. **Services** will be mapped to **ports**, exposing those services. For instance, youâ€™ll see **port 9000** being used, where the service is available.
3. **Port Forwarding** will direct traffic from port 9000 to the corresponding pod, allowing you to interact with the UI.
4. The **ReplicaSet** will ensure that your **deployment** is properly scaled, using one of the pods to run the process.
The **UI** will be accessible through the port forwarding configuration, visible and accessible via the port mapping (9000).

#### **LO1-V23:DIAGNOSE-AND-LEARN-FROM-ERRORS ğŸ§ ğŸ’¡**  
Errors *are* learning opportunities. [SHOW] In Kubernetes, unexpected errors like "unhandled error" will occur as systems initialize. These failures are clues, and understanding how to diagnose them is critical.  
[DO] Use the AI to help you break down errors, such as memory issues (e.g., adjusting the `VM Max Heap Count`). As you debug, gain familiarity with system variables, kernel settings, and Kubernetes configurations. These hurdles are your "gold mines"â€”they guide you toward better solutions. Embrace them as a tool for growth. Learn, iterate, and perfect your stack. ğŸ’»ğŸ”§

#### **LO1-V24:MANUAL-TO-AUTOMATED-DEBT-PAYMENT ğŸ”„ğŸ’»**  
Manual fixes *lead* to automation. [SHOW] Start by managing technical debt manuallyâ€”before SonarQube suggests improvements, take the time to manually identify and resolve issues in your system. This is an essential step to truly understanding the problems at hand.  
[DO] Document each manual fix thoroughly. As you become comfortable, integrate SonarQube to automate debt management. Then, set up a digital dashboard to track your progress. This approach ensures youâ€™re learning the process, not just relying on the tool. Pay down debt both manually and automatically, and see your system improve with each step. ğŸ“ŠğŸ’ª

#### **LO1-V25:YAK-SHAVING-AND-DEBT-PAYMENT ğŸ› ï¸ğŸ”§**  
Tech debt *requires* sacrifice. [SHOW] It's easy to wonder, â€œWhy am I learning all these concepts when my goal is just to use SonarQube?â€ The answer is yak shaving. Sometimes, solving a problem means going out of your way to clear obstacles. This *manual* debt payment lays the foundation for a smoother system.  
[DO] Embrace the process. Understand that paying down technical debt manually is crucial. By learning this, youâ€™re preparing your system to scale and improve in the long run. Get comfortable with manual fixes, and donâ€™t shy away from the extra workâ€”itâ€™s the path to better infrastructure. ğŸ§¹ğŸ’¡

#### **LO1-V26:MANUAL-TECH-DEBT-PAYMENT-STRATEGY ğŸ’»ğŸ“š**  
Manual tech debt *demands* precision. [SHOW] To pay it, start by creating a **`semblance`** folder using a markdown structure. In it, document your strategies, such as the YAML configurations and prompts.  
[DO] For each error, write down your troubleshooting steps and solutions. Keep iterating and adding the AIâ€™s responses along with the output until the issue is resolved. Regularly commit your changes and share them in an open-source manner for peer feedback. This is the process of manual tech debt paymentâ€”stay disciplined and refine the system step-by-step until youâ€™re ready to turn it on. ğŸ“œğŸ”§

#### **LO1-V27:USING-MULTIPLE-AI-ENGINES-FOR-TECH-DEBT-PAYMENT ğŸ¤–ğŸ”„**  
Paying technical debt *manually* involves leveraging multiple AI engines. [SHOW] Your primary choice is **CoPilot** on GitHub Codespaces, but when context grows, expand to other models like **Croc** for handling larger inputs and more complex error messages.  
[DO] As you solve issues, document all solutions, append the AI-generated responses at the bottom, and commit changes to version control. By using a mix of AI platforms, you enrich the troubleshooting process and improve static analysis within SonarQube. Always address problems manually before automating solutions with SonarQube. This iterative approach ensures precision and deeper understanding. âš™ï¸ğŸ’¡

#### **LO1-V28:FOLLOW-THE-STRUCTURE-TO-FIND-ANSWERS ğŸ“ğŸ§­**  
Your core documentation lives in Markdownâ€”structured with `#` headings and iterative updates. [SHOW] When a pod fails, you **log the pod ID**, append context, and refeed it into GPT for debugging.  
[DO] Stick to the folder logic:  
- `semblance/`: system state & errors  
- `formulas/`: GPT prompts  
- `ui/`: screenshots & frontend views  
- `real/`: OKRs  
Before asking questions, **read commit histories**â€”they're stories in disguise. This discipline helps you respect the past effort and guide your debugging with clarity. Everything has a place; every folder helps you navigate the chaos. ğŸ“˜ğŸ’¾

#### **LO1-V29:EMBRACE-K8S-WITH-AI-FIRST-MINDSET â˜ï¸ğŸ¤–**  
Namespace grouping in Kubernetes is essentialâ€”especially when managing an AI-first SonarQube deployment. [SHOW] All your YAML, pod configurations, and executions are AI-generated.  
[DO] Treat `kubectl` as your lens: inspect pods, track failures, and feed issues into GPT. Learn to ask the right questionsâ€”**GPT is your DevOps pair**. SonarQube instances from 2020s onward often live in Kubernetes clusters, so mastering this environment is non-negotiable. Start small, debug fearlessly, and leverage AI to build confidence in navigating and fixing K8s systems. ğŸ§ ğŸ”§

#### **LO1-V30:SMART-AI-STACK-SELECTION ğŸ¤¹â€â™‚ï¸ğŸ§ **  
Not all AI engines are freeâ€”**use them strategically**. [SHOW] Your default coding assistant might be GitHub Copilot (tight Codespaces integration). But when your prompts grow or tasks get complex:  
- Use **Grok** for long-context analysis.  
- Switch to **Claude** for structured reasoning and complex YAML/log debugging.  
[DO] Treat your AI tools like a toolboxâ€”**swap based on the problem**. Monitor quotas, understand each modelâ€™s strength, and rotate wisely. This agility turns you into an AI-native developer who can balance budget, capability, and context depth. ğŸ§°ğŸ’¡

#### **LO1-V31:INTUITION-IS-YOUR-SUPERPOWER ğŸ§­âœ¨**  
Your intuition *rocks*â€”trust it. [SHOW] In this M-shaped world (multi-domain, multi-tool), AI gives suggestionsâ€”but **you** connect the dots. While paying off tech debt manually, enjoy the craft. This is where your **intuition trains reliability**.  
[DO] When AI responds, pauseâ€”**sense-check** it. Use what *feels right* to explore deeper. When systems fail (and they will), itâ€™s human insight that rebuilds trust. Learn the rhythms, enjoy the mess, and remember: **manual mastery builds mental resilience**. Reliability isnâ€™t magicâ€”itâ€™s born from your thoughtful, repeated actions. ğŸ› ï¸ğŸ§ â¤ï¸â€ğŸ”¥

#### **LO1-V32:DEPENDENCY-AWARE-MANUAL-DEBT-PAYMENT â›“ï¸ğŸ““**  
We all have dependencies. [SHOW] In this case, GitHub Codespaces and Minikube are your *infrastructure lifelines*â€”but theyâ€™re fragile. Codespaces expire. Clusters break. And with that, your setup disappears.
[DO] Thatâ€™s why you **document and rebuild**. The *manual debt payment system* means: **you become the SonarQube**. You track issues. You write logs. You notify yourself. This isnâ€™t just DevOpsâ€”itâ€™s **self-reliance** engineering.
Every folder in your delivery pilot matters. Every error you document is a breadcrumb back to stability. Youâ€™re not automating yet. Youâ€™re earning your understanding. **Rebuilding is your rite of passage.** ğŸ§±ğŸ§â€â™‚ï¸ğŸ“’

#### **LO1-V33:VERIFY-WITH-AIâ€“RUBBERDUCK-EVERYTHING ğŸ¦†ğŸ¤–**  
Always **verify with AI**. [SHOW] Everything you touchâ€”from Kubernetes configs to machine specsâ€”deserves a question. Not just because AI knows, but because **you learn by asking**.
[DO] This is called the **Rubberduck Process**:  
You go from **UNKNOWN â†’ KNOWN** by saying things out loud (or in prompts).  
Example:  
> *"I want to set up SonarQube in Minikube using Codespaces. Which machine type should I select?"*  
That's not weakness. Thatâ€™s *clarity creation*. You're making fog into form. And the better your questions, the sharper your answers. Use CoPilot, Claude, GPT, Grokâ€”whatever engine you need.  
ğŸ” *Ask. Verify. Re-ask. Learn.*  
ğŸ§  The conversation *is* the build.


#### **LO1-V34:SONARQUBE-IN-MINIKUBE-ON-CODESPACES ğŸ–¥ï¸ğŸš€**  
Weâ€™re spinning up SonarQube inside Minikube on Codespaces. This is a memory-intensive N-tier system, so make sure your machine starts with 4 CPUs and 8GB RAM. Run the starter script, watch the pods, and document everything â€” unknowns, AI questions, YAML tweaks.
Use Copilot for inline help and escalate to Grok or Claude for longer outputs. Every error is a gold mine â€” follow the Rubber Duck method: ask smart questions and move from UNKNOWN to KNOWN. Youâ€™re not just coding, youâ€™re learning to debug with AI. Letâ€™s build!

#### **LO1-V34:MONITORING-VIRTUAL-MACHINE-RESOURCES ğŸ–¥ï¸ğŸ”**  
To understand whatâ€™s happening in your virtual machine as a Linux cell, use the `top` command. This shows you running processes, including SonarQube-related and DNS processes, along with memory and CPU usage. **Unknown** is a state where more space equals better performance, but **known** means you've allocated RAM and CPU resources for both the host and Minikube. Ensure thereâ€™s enough space for both to operate effectively. Running SonarQube requires significant memory and CPU to load the system, run scans, and generate results. **This is a memory and CPU-intensive process** that demands careful resource management.

#### **LO1-V35:MONITORING-SYSTEM-PROCESSES-AND-CONTAINERS ğŸ› ï¸ğŸ“Š**  
After spinning up your system on HWAP, check the containers. You'll see some are still creating, while others are running. The critical containers to monitor are **SonarQube** and **SonarQube Database**. The **SonarQube Database** stores your records, which you may need to back up in an enterprise environment. The **SonarQube UI** and business layer handle scans. The **Unknown** state refers to the container's running state, which you should check regularly. Think of it like checking the Task Manager on Windows or the Terminal on macOS. Use `kubectl get all -n sonarqube` to check all objects in the SonarQube namespace. Always monitor these to stay aware of your systemâ€™s health.

#### **LO1-V36:MONITORING-SYSTEM-INITIALIZATION-AND-DEBUGGING ğŸ”„âš™ï¸**  
Monitoring SonarQubeâ€™s system initialization requires you to understand both its success and failure states. [SHOW] After launching, check the `localhost:9000` URL in GitHub.dev to confirm that SonarQube is up and running. The system will initialize, but donâ€™t be surprised if it failsâ€”common issues include database or load balancer problems.  
[DO] Document every error or failure you encounter and update your Git project regularly. Each problem provides valuable learning, and capturing the UI state when it loads successfully helps track progress. Debugging and re-running steps ensure a deeper understanding of how to keep the system operational.

#### **LO1-V37:VERIFYING-SONARQUBE-PORT-FORWARDING-AND-CONNECTIONS ğŸŒğŸ”**  
Once SonarQube is running, youâ€™ll observe port forwarding activity in the terminal, specifically handling connections to port `9000` for each incoming request. [SHOW] This indicates that the system is up and running.  
[DO] The unknown here is what might happen behind the scenesâ€”whether the system will function smoothly or encounter issues. However, youâ€™ll know itâ€™s operational when you see active requests in the port forwarding logs. Even though you canâ€™t see everything in the background, tracking these logs ensures you understand the traffic flow and the connection status in SonarQube.

#### **LO1-V38:AVOIDING-LOST-CONFIGURATION-AND-BACKING-UP-SONARQUBE-SETUP ğŸ› ï¸ğŸ’¾**  
Losing configuration is one of the worst setbacks you can face. [SHOW] When GitHub Codespaces gets destroyed, all the configurations youâ€™ve set upâ€”especially how SonarQube connects to the agent and GitHubâ€”will be lost. Your Minikube runner, which connects to GitHub via the SonarQube setup, will be severed.  
[DO] To prevent this, use tools like **LastPass** and **Obsidian** for secure, easy-to-access documentation. Keep a Markdown file with your configuration details and update it regularly. This manual process of documenting your setup becomes your technical debtâ€”ensure you follow your markdown to recreate the system whenever needed. By doing this, you can confidently restore or reconfigure the system without losing crucial setup details.

#### **LO1-V39:CONFIGURATION-DOCUMENTATION-IN-OBSIDIAN-AND-LASTPASS ğŸ“šğŸ”**  
To prevent losing track of your configurations, use **Obsidian** as your second brain and **LastPass** for secure storage. [SHOW] Store all your configuration details in Obsidian, linking and tagging each entry for easy retrieval. If you need extra security, keep critical information in **LastPass** or a secure text file. For open-source projects, make sure sensitive data is **.gitignored** and not exposed in repositories.  
[DO] Organize your notes by tagging and linking them for easier access, ensuring you can quickly locate the configuration details needed to rebuild the system. Remember, if you have a large knowledge base (like 1.1 million words in Obsidian), the key to avoiding overwhelm is well-structured links and tags. Documenting and linking configurations will reduce your technical debt and make it easier to recreate your systems in case of failure.

#### **LO1-V40: CONFIGURATION MANAGEMENT AND MAINTAINING RELIABILITY ğŸ› ï¸ğŸ”„**  
Managing configurations efficiently is key to reducing errors. [SHOW] I create a template for my configuration, with placeholders like "xxx", that I update regularly. Each time itâ€™s updated, I store it in my second brain â€” whether itâ€™s LastPass, Obsidian, or another secure location. By doing this, I minimize errors and maintain a reliable system.  
[DO] Start from the *Unknown* and focus on what could fail next. While you have your *Known* â€” the complex multi-stage configuration â€” always be aware that unexpected changes can happen, and new issues may arise. Systems with many moving parts, like this one, require constant attention to whatâ€™s beyond your immediate control, and the key is to stay proactive in solving what may fail next. By tracking these changes and knowing where to find your updated configurations, you ensure youâ€™re always one step ahead in keeping your system stable.

#### **LO1-V42: EXTERNAL ACCESS AND SYSTEM VISIBILITY IN MULTI-COMPONENT SETUPS ğŸŒğŸ”**  
External access to your systems, like Obsidian on Codespaces, plays a crucial role in enabling integration with platforms like GitHub Actions. [SHOW] You need to manage the visibility of your components â€” deciding which ports are public or private â€” to ensure smooth communication with these external systems. Webhooks are vital for sending events back to you, so you can monitor your progress.  
[DO] Document all the URLs, events, and errors in a structured folder like "semblance". When things donâ€™t work, donâ€™t ignore them; this is your *Unknown*. As part of your *Known*, you should constantly assess your multi-stage configuration and track any issues. Use AI to read through your logs and help diagnose where you got stuck during the SonarQube setup or operations. Regularly update your documentation, index it, and make sure you can trace your history easily, ensuring that each step of your debugging journey is well-documented.

#### **LO1-V43: HANDLING DYNAMIC URLS AND CALLBACK CONFIGURATION ğŸŒğŸ”„**  
One common mistake when setting up SonarQube on Codespaces is missing the correct port number. [SHOW] In the beginning, I forgot to include the port in my callback URL, which caused issues when trying to send events back to SonarQube. The dynamic nature of the Codespaces load-balanced URL means it changes each time you create the service, so the callback URL needs to be publicly accessible to ensure webhooks can communicate with your SonarQube instance.  
[DO] Always make sure to update these URLs in your integration systems when you notice that the load-balanced URLs have changed. Your *Unknown* is what might fail, like missing port numbers or broken callbacks, but your *Known* is the process you go through: recording and revising each failure as it happens. Keep track of the history of changes and errors in your documentation. This enables you to identify what went wrong, how to fix it, and how to proceed confidently in the future.

#### **LO1-V44: CONFIGURING SONARQUBE ENVIRONMENT VARIABLES ğŸ› ï¸ğŸ”**  
When integrating SonarQube with GitHub, setting the correct environment variables is crucial.
[SHOW] Pay close attention to the **Sonar Token** and **Sonar Host URL** â€” these two environment variables must be correctly configured in GitHub Secrets for the integration to work properly. The **Sonar Token** is your authentication key, and the **Sonar Host URL** points to where your SonarQube instance is running.  
[DO] As you work through these configurations, remember that your *Unknown* is which environment variable might cause issues, but your *Known* is the systematic recording of each configuration change. Store the values in your systemâ€™s config file and document each step in your markdowns. This helps ensure that if anything goes wrong, you can refer back to your detailed logs and correct the problem based on your documented history.

#### **LO1-V45: HANDLING CODESPACES RESET AND ENVIRONMENT VARIABLE MANAGEMENT ğŸ”„ğŸ”§**  
In Codespaces, losing data or restarting can require resetting key environment variables.
[SHOW] When you lose access to your Codespace, youâ€™ll need to recreate the environment variables, such as the **Sonar Token** and **Sonar Host URL**, because these URLs change every time the Codespace is reset. This process gives you the opportunity to practice updating and managing GitHub Secrets and environment variables.  
[DO] Your *Unknown* here is which environment variable may fail, but your *Known* is the process of carefully updating these values when Codespace is reset or lost. Always document these changes, as this will help ensure your GitHub Actions integrate properly, and you'll be able to track the movement of components like SonarQube through every reset.

#### **LO1-V46: MANAGING SONARQUBE PROJECT KEY ROTATION ğŸ”‘ğŸ”„**  
In Codespaces, each new SonarQube setup creates a fresh database, resulting in a **new project key**. [SHOW] The project key will change every time you initialize a new SonarQube instance, which can be challenging to predict. The key is a global unique identifier for your SonarQube project, and youâ€™ll need to be ready for it to rotate each time you set up.  
[DO] Your *Unknown* here is the unpredictable nature of the project key change, but your *Known* is that this key will change with every new SonarQube project. Save the updated key in the `sonar-project.properties` file at the root of your project so SonarQube knows which configuration to apply. By tracking and documenting this change, you ensure smooth integration and avoid disruption in your workflow.

#### **LO1-V47: SONARQUBE STATIC ANALYSIS AND THE HUMAN TOUCH ğŸ§ ğŸ’»**  
Once youâ€™ve set the variables and integrated your SonarQube system, it will monitor your project and perform **static code analysis** to identify **technical debt** in your codebase. 
[SHOW] SonarQube will scan the project and provide feedback on areas that need improvement, offering a thorough report on issues like bugs, vulnerabilities, and code smells.  
[DO] The *Unknown* here is which parts of your project will need the most attention during each scan, as it may vary with every new build or feature added. Your *Known* is that as long as the configuration keys are correctly set and the system is running, SonarQube will be ready to perform its scans and notify you of any issues. Remember, while AI plays a crucial role in identifying technical debt, **human intuition** is essential for interpreting results and making change approvals.

#### **LO1-V48: SONARQUBE TRIGGERS AND NOTIFICATIONS ğŸ“ˆğŸ””**  
The key to triggering SonarQube scans is based on **commit saves**. [SHOW] In enterprise environments, the frequency of scans can vary, with some companies opting for scans after every commit, others after every hour, or for certain branches. These decisions depend on the number of commits, the resources available, and the business rules they have in place.  
[DO] The *Unknown* is when exactly the scan will be triggered, as it can vary based on factors such as the frequency of commits and the team size. Your *Known* is that SonarQube scans rely on an agent running within the **GitHub actions** pipeline, and youâ€™ll receive success reports with notifications. These reports will guide you on what changes need to be made to improve your codebase, making it essential to stay up-to-date with notifications to understand where changes are required.

#### **LO1-V49: MONITORING GITHUB ACTIONS AGENT ğŸ–¥ï¸ğŸ”**  
To monitor your **GitHub actions** agent, 
[SHOW] navigate to your **GitHub repository**, then click on the **Actions** tab. Here, youâ€™ll see the status of various workflows. If the status is **yellow**, the action is running; if itâ€™s **red**, the action has failed; and if itâ€™s **green**, the action has passed.  
[DO] The *Unknown* is which actions will fail, and the *Known* is that the color-coded status helps you quickly identify whether an action is running successfully. When dealing with many repositories and workflows (over 100+), this can become a complex matrix of actions running in the background. Focus on the notifications and investigate the failures to understand why they occur. This is part of the **yak shaving** process, where you delve deep into the components to ensure everything is functioning smoothly.

#### **LO1-V50: UNDERSTANDING THE FIRST SUCCESS AND MONITORING CODE QUALITY ğŸŸ¢ğŸ“Š**  
The first moment of success is when you see your **SonarQube project pass** and gain insights into your project's coverage and duplications. [SHOW] A **green** status indicates your project is performing well, and youâ€™ll be able to see the lines of code covered, duplicated code, bugs, vulnerabilities, and other issues detected.  
[DO] The *Unknown* is when your project will successfully pass, as there may be fluctuating factors. The *Known* is that once SonarQube runs, it will show static code coverage, and you can drill down into issues. Address the **bugs, vulnerabilities, code smells**, and **duplicated code**â€”this is your technical debt to pay off. Be mindful that **paying off technical debt** requires time and effort, and there's always a cost in terms of resources and focus to ensure long-term code health.

#### **LO1-V51: TRACKING TEST COVERAGE AND IMPROVING CODE QUALITY ğŸ§ªğŸ”**  
When reviewing reports, **test coverage** is crucial to assess if your code is adequately tested. [SHOW] SonarQube will highlight **covered lines** and test failures, but remember that setting up tests for all projects may not always be feasible.  
[DO] The *Unknown* is understanding what parts of your code might fail in testing, especially in complex environments with multiple teams and projects. The *Known* is that **static analysis** tools like SonarQube help identify coverage gaps, errors, and failures. By recognizing areas for improvement, you can enhance your **test coverage** to ensure your codebase becomes **robust** and **anti-fragile**, ultimately making it more **releaseable** and trustworthy.

#### **LO1-V52: CREATING AND HANDLING ARTIFICIAL FAILURES FOR TESTING ğŸ”§âš ï¸**  
You can create intentional **failing statuses** to test your system's resilience. [SHOW] Use AI to simulate a **division by zero error**, which is one of the simplest errors to check. For instance, using `print(a / b)` where `b` is 0 will trigger a **divide by zero** error.  
[DO] The *Unknown* is whether this artificial failure will occur as expected, so understanding how these errors impact your system is critical. By mastering error handling and failure simulation, you can strengthen your test coverage and ensure the system behaves predictably, even in edge cases. This process will help you **validate error-handling workflows** and **improve system reliability**.

#### **LO1-V53: SCALING INTENTIONAL ERROR CREATION FOR RELIABILITY TESTING âš¡ğŸ’»**  
Once your package is optimized, you can introduce **intentional errors** (like division by zero) anywhere in your codebase. The **Unknown** here is how many test cases (or failure scenarios) you need to account for. **SonarQube** gets updated, and there are **many edge cases** beyond just dividing by zero that could cause issues.  
[DO] You can scale this testing by simulating multiple types of failures across different parts of your system. The goal is to test **SonarQube**'s ability to handle various errors. By automating these tests and ensuring that **SonarQube** properly identifies these failures, you validate the **reliability** of your system.  
Test your errors systematically and regularly to ensure the system remains **stable and resilient** even as the code evolves and new configurations are introduced.

#### **LO1-V54: PAYING DOWN TECHNICAL DEBT WITH SONARQUBE ğŸ“‰ğŸ’¡**  
As you add new features to your project, **SonarQube** will flag an increase in **vulnerabilities**, **security hotspots**, and generate **risk grades** (A, B, C, D, E). These metrics are critical in tracking the **technical debt** as it accumulates, and understanding them helps you decide when and how to address issues.  
- **Unknowns**: The timing of when you will run out of resources or when the debt becomes unmanageable.
- **Knowns**: The **gradual increase in technical debt**. If you don't actively manage it, it will continue to grow and become harder to handle later on.
The process you need to focus on is your ability to manage this **debt** by using SonarQube reports and paying down the debt. This cycle, often called the **STLC (Software Testing Life Cycle)**, emphasizes the need for **continuous improvement** and regular maintenance to keep the project scalable, secure, and efficient.
**Takeaway**: Ensure you're constantly **monitoring**, **addressing**, and **prioritizing** issues flagged by SonarQube so that the technical debt doesn't overwhelm your system.

#### **LO1-V55: MANAGING TECHNICAL DEBT FOR AGILITY IN THE SOFTWARE DEVELOPMENT LIFE CYCLE ğŸ”„ğŸ’¼**
In the **Software Development Life Cycle (SDLC)**, managing **technical debt** is critical for ensuring that your system remains **agile** and **adaptable** to change, such as new features or contracts.  
[SHOW] SonarQube will display your **vulnerabilities**, **code smells**, **duplicated code**, and overall **technical debt**, helping you track and manage these issues throughout the development process.  
[DO] The *Unknown* is how quickly the technical debt will accumulate and when it will become a barrier to progress. The *Known* is that **static code analysis** tools like SonarQube can **identify and quantify** this debt, allowing you to make informed decisions about **paying down** the debt before it negatively impacts system agility. 
By proactively addressing technical debt, you maintain the **agility** of your software, enabling you to add new features and scale without compromising the stability of the codebase.

#### **LO1-V56: TRACING FAILURES THROUGH GITHUB ACTIONS AND IMPROVING ARCHITECTURE ğŸ”§ğŸš¦**
Every time you make a commit, it triggers a workflow. [SHOW] GitHub Actions will display each commit ID and the associated pipeline status: âœ… (success), âŒ (failure), or ğŸŸ¡ (in progress). This lets you monitor whatâ€™s happening with each change in real-time.
[DO] The *Unknown* is **where** it might fail â€” could be the GitHub agent, the host environment, SonarQube, or your actual codebase. The *Known* is that you can now **trace** the full pipeline and identify **which component** caused the failure. By systematically investigating and fixing issues, you not only eliminate bugs but also **strengthen your architecture** and reduce **technical debt** over time.
This repetitive troubleshooting becomes your training ground â€” the more you fix, the more resilient and maintainable your codebase becomes.

#### **LO1-V57: UNDERSTANDING LINE COUNTS AND INTENTIONAL FAILURES ğŸ“âŒ**
When working with SonarQube and code analysis tools, [SHOW] **total lines of code** and **covered/uncovered lines** become key indicators of your projectâ€™s size and testing depth. Whether youâ€™re working with a 100-line prototype or a million-line monolith, the scale changes how you approach test coverage.
[DO] The *Unknown* is why certain errors, like an intentional `divide-by-zero`, **donâ€™t fail** as expected â€” is it the test setup, the analysis timing, or the coverage scope? The *Known* is that **basic errors should fail**, and if they donâ€™t, that tells you something critical about your validation pipeline. Injecting intentional bugs helps you verify that **your fail-safes actually fail** when they should, and ensures that real bugs won't silently pass through.

#### **LO1-V58: HANDLING AUTO SHUTDOWNS AND CALLBACK FAILURES IN CODESPACES âš ï¸ğŸ§µ**
In dynamic environments like Codespaces, [SHOW] **auto shutdowns** can unexpectedly disrupt your system, especially if your SonarQube **callback URLs** or agent resources are tied to ephemeral infrastructure. When Codespaces reset, your callback URLs and **GitHub Actions agents** may lose access, breaking the feedback loop from SonarQube.
[DO] The *Unknown* is **when** a failure occursâ€”during a shutdown, a callback attempt, or due to resource exhaustion. The *Known* is that your system involves **multiple moving parts** (host, agent, SonarQube, callbacks). Track them through your logs, GitHub Actions panel, and resource dashboards. If this is **proof of concept**, you can debug and reset. If this is **production**, consider stabilizing infrastructure with **Infrastructure as Code (IaC)** or persistent cloud services to avoid such fragility.

#### **LO1-V59: TRADE-OFFS BETWEEN PAID SERVICES AND TECHNICAL DEBT MANAGEMENT ğŸ’¸ğŸ”„**
In your workflow, 
[SHOW] **paying for persistent cloud resources** (like always-on Codespaces or enterprise SonarQube) is a way to avoid sudden shutdowns and maintain continuity. However, it shifts the pressure to **monetary investment**, accelerating the need to move beyond the **Proof of Concept (PoC)** stage.
[DO] The *Unknown* is **how much** money or time is needed to support a reliable, always-on infrastructure. The *Known* is that **every unpaid service has limits**â€”just like **technical debt**, if ignored, these systems will eventually **expire or break**. Learn to distinguish:
- **PoC**: Short-term testing, cheap, fragile.
- **Prototype**: Feature exploration, still flexible but more refined.
- **Pilot**: Limited launch with monitoring, investment-ready.
- **Production**: Stable, optimized, and must be funded and supported.
Just like choosing which **code issues to refactor**, you must make **strategic trade-offs** on what infrastructure to pay for now, and what to defer until the system or team is more mature.

#### **LO1-V60: WRAPPING UP â€“ FROM TECHNICAL DEBT TO DAILY DEPLOYMENTS ğŸš€ğŸ§°**
[SHOW] As we close this session, remember the **real goal** isn't just to analyze code qualityâ€”it's to build a **healthy release pipeline** where daily deployments are possible, technical debt is manageable, and everyone in the team benefits from a smooth developer experience.
[DO] The *Unknown* is **how fast you can move without breaking things**â€”because growth means more features, more users, and more pressure. The *Known* is that **doing the work now** (yes, your assignments and hands-on practice!) will equip you with the tools to:
- Monitor code quality
- Understand failures
- Fix fast
- Deliver continuously
Youâ€™ve got this. Letâ€™s keep buildingâ€”and stay connected for **future courses** where we dive into **AI-assisted deployments**, **microservice architecture**, **zero-downtime rollouts**, and more.
ğŸ¯ _â€œTechnical debt is like financial debt. Ignore it, and the interest compounds. Face it, and your future becomes freer.â€_

