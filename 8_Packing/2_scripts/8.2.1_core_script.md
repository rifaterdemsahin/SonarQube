# Core Script

```yaml
video_script:
  Content: "[]"
  prompt: 
    - "One page compatible with Elgato prompter"
    - "Text output use emojis"
    - "Expand or shrink for 100 words"
    - "Do not repeat the same words"
    - "Do not update [[]] for obsidian reference"
    - "For each slide rewrite and fix syntax for the prompter > target 100 words"
    - "Header formart L01-v1-[summarycontent]-tell-show "
    - "Example: #### **LO1-V4:START-GITHUB-ACTIONS-WITH-YAML-TELL-SHOW** âš™ï¸  
To get GitHub Actions running, start with a **simple YAML workflow**. [SHOW] YAML (Yet Another Markup Language) is the backbone of most modern platform configurationsâ€”essential for defining CI/CD pipelines, infrastructure, and deployment rules.  
[DO] I recommend using **GPT to help generate or review** your YAML files. In this repo, all prompts and examples are GPT-assisted. Ask it to explain or **add comments** if anything feels unclear. This makes your workflows not just functional, but understandable. YAML is your **config language for infra**, so mastering it will pay off across platforms. ğŸ§ ğŸ“"
    
```
####### todos
- remove tellshowdo from the script and beatboard index as integrated in all
- check the index at the top
- set the headers with lo lo2 lo3 intro promo with markdown
- fix the naming to v10 v31
- practice energy with hand printed notes
- show and do one liners
-  show and do new lines

## Text Output >

### Active Script 
##### Intro-S1-Hook
Welcome to our [[SonarQube]] course!
In todayâ€™s fast-paced world, delivering high-quality software isnâ€™t just about writing code.
itâ€™s about [[Connecting Dots]] catching issues early and keeping [[technical debt]] in check.
With [[SonarQube]] course, youâ€™ll learn how to add your projects to integrate them for analysing of code, and ensure release readiness throughout your [[development lifecycle.]]
Most important of all we would be able to learn to fix the issues in first principles based approach to fix it.
Letâ€™s get started and transform the way [[you approach software]]!

##### Intro-S2-Objective
In this course, you'll master:
- Setting up SonarQube in a development environment - [[elephant eat it first]]
- Integrating [[SonarQube project]] CI/CD pipelines - enter into the world of [[fixing is at core]] pay the infra debt
- [[Analysing code quality]] and [[security vulnerabilities]] - with change


##### Intro-S3-[[Flex]]  
Hello, I'm Rifat Erdem Sahin. With over 40 successful [[IT contracts]] and [[80 projects]] delivered globally, I've honed deep expertise in the [[software development life cycle]]. At Accenture, it was the pivotal tool in my journey, which has enabled me to ensure code quality and maintainability across [[projects million man day projects]]. Integrating SonarQube into CI/CD pipelines has streamlined continuous integration to support trunk-based development for rapid, reliable code releases. In an ever-changing world, let's dive in and learn the components needed to make it work.

#### **INTRO-V3.A:REAL-WORLD-EXPERIENCES-AND-LEARNING-TO-THRIVE IN-TECH-DEBT ğŸš€ğŸ”§**  
In this course, expect a real-world perspective, not just theory. [SHOW] Iâ€™ll guide you through necessary "yak shaving" â€” yes, itâ€™s part of the journey, and itâ€™s all about learning to navigate the technical debt. Iâ€™m not here as an AI-driven guide, but as someone who's worked through these challenges and successfully delivered projects.  
[DO] Iâ€™ll share my personal experiences, the tips, and tricks Iâ€™ve used to tackle SonarQube and beyond in real-world projects, focusing on daily deployments and technical debt resolution. This isnâ€™t automated content; it's built from hands-on learning. I want to help you innovate in ways that my younger self would have appreciated, and through this course, I hope youâ€™ll gain both the knowledge and confidence to solve real-world tech challenges.

##### Intro-S4-Bonus
We're diving into an [[AI-first project]] where you'll harness the power of AI tools[[4.1_Iterated_prompts_onClaude]] to set up and optimize your own [[SonarQube environment]]. Along the way, you'll [[sharpen your skills]] in [[AI-assisted development]] and ensure your workflows meet top-tier quality standards. By the end of this course, youâ€™ll not only understand how to [[integrate]] AI into your software development pipelineâ€”youâ€™ll also be confidently applying it for fixing continuous integration and automated quality checks with tools like SonarQube. Bonus: Youâ€™ll walk away with a fully functional, portfolio-ready project to showcase your skills to the world!

##### Intro-S5-portfolio-apply
[Check out LinkedIn for the projects that i have used the sonarqube to pay the technical debt and contracts that are mentioned here. Also follow the links to go to GitHub where I am sharing all the code that is needed for this course and check out the portfolio projects over there. Building a portfolio on GitHub for IT professionals matters, and SonarQube would complement it by making sure the quality of the software meets the requirements for the customers who are seeking easily updatable applications at high quality.]("8.3.LinkedinAndGitHub.mp4")

##### Lo1-v1-s1-whatsissonarqubet-tell-show
What is SonarQube and Why Do We Need It?
SonarQube is an essential tool in modern software development. Think of software as a buildingâ€”it's not just about constructing it but maintaining its quality over time. In the Software Development Life Cycle [4.20.1_sonarqube_cycle.png](SDLC), technical debt accumulates as new requirements emerge. This is a normal part of development, but managing this debt effectively is critical.
The SDLC helps us package and address technical debt until new requirements arise. The key question is: when do we tackle this debt, and how do we allocate time for it? For a project to move forward, we need a structured process to measure and manage technical debt, much like using a scale to track progress.
In todayâ€™s fast-paced world, AI is accelerating the rate of change, making it even more important to have tools like SonarQube. It provides a clear environment to measure, analyze, and reduce technical debt, ensuring your software remains maintainable and scalable.

##### Lo1-v1-s1-sonarqube-benefits-tell
SonarQube offers a comprehensive view of your code quality, helping you maintain high standards and improve your development process. Here are four key benefits:
- **Multi-language Support**: SonarQube supports more than 25 programming languages, making it a versatile tool for diverse development teams.
- **Team Collaboration**: SonarQube helps maintain a standard of code quality within your development team, fostering better collaboration and consistency.
- **Debt Management**: By identifying and addressing technical debt, SonarQube allows you to focus on adding new features while keeping your codebase maintainable.
These benefits make SonarQube an essential tool for modern software development.
- **CI/CD Integration**: It seamlessly integrates into your CI/CD pipeline, enabling continuous code quality checks with every commit.Elephant we need to sort out!

##### Lo1-v2-s1-Setup pick environment-tell-show 
Our initial objective is to set up the environment effectively. The most challenging setup will be for production, but in this course, we are focusing on building a portfolio and presenting your ideas confidently. To achieve this, we will concentrate on Proof of Concept environments, which are primarily infrastructure-as-code-based setups such as Codespaces.
While choosing the environment, itâ€™s natural to have preferences. For instance, I am building this course on [4.2_windows_structure_install.png](Windows) but have chosen to work on Codespaces. The key takeaway is to learn how to restore and fix SonarQube components by applying first principles. This foundational knowledge mixed with AI first implementation will empower you to handle any environment with confidence.

##### LO1-v2-s2-shortcuts-tell-show
The ultimate shortcut is to use a [4.18.1_cloud_implementations.png](cloud-based rental system) for SonarQube. This eliminates the need for setup, allowing you to quickly start scanning projects. While this approach is convenient, itâ€™s crucial to understand the deployment components, as SonarQube is often used in enterprise environments. Learning these fundamentals ensures a first-principles approach, enabling you to adapt to various project requirements. Weâ€™re focusing on this method not because itâ€™s easy, but because mastering the setup process builds a deeper understanding. This knowledge is invaluable, especially when working with dynamic environments like Codespaces, which can be ephemeral by nature.

##### LO1-v2-s3-infradebt-tell-show  
SonarQube is a tool for managing technical debt, a critical yet often overlooked concept in IT. Technical debt refers to the compromises made in infrastructure or code that may lead to future challenges. In this course, we rely on GitHub Codespaces to host processes for running SonarQube. While the free tier contract(debt) offers a limited timeline, it introduces potential trade-offs, such as resource shutdowns. Students should focus on understanding these trade-offs and learning how to restore components when needed. [4.19.1_codespacescost2025April.png](For basic usage in this course,) the free tier suffices, but exceeding limits may incur additional costs. Manage resources wisely!

##### LO1-v2-SettingUpEnvironment-tell  
For most students, accessing the environment requires virtualization. Setting up the environment is our primary goal and a critical task. We should approach it in a way that allows us to rebuild it with ease. This is about becoming skilled, and I wasnâ€™t always in that position. Initially, I looked for shortcuts, but Iâ€™ve come to realize that this is one of the harder yet more meaningful ways to build it.  
The system we are building will face challenges staying online, but these challenges will provide valuable learning opportunities. My proof-of-concept choice is Linux and a cloud-based solution called Codespaces, which has a strong community behind it.  
As a side note, this might feel like a bit of "yak shaving," but this Kubernetes and cloud-based vision will pay off for IT professionals in the long run. Trust me, I was once skeptical of this approach, but it has proven to be invaluable.

##### LO1:v3:linuxBased-Show-Do
Our pick is GitHub Codespaces. First, create your GitHub account, repository, and Codespaces environment on the GitHub platform. Our goal is to access the Minikube resource, which has already been deployed there. The free account provides temporary access to run the `minikube start` command. 
There are no excuses, such as not having access to a machine or being unable to open a GitHub repository. Codespaces offers a portfolio-ready environment for IT professionals, including tools like GitHub Actions. 
Please open the terminal, run the command, and watch Minikube go online. Once it's running, we can proceed to install the SonarQube platform on it.

##### LO1-v3-Codespeaces-Terminal-Getting-UsedTo-Tell-show
When you're inside Codespaces with Minikube, youâ€™re operating through multiple layersâ€”your machine, the Codespaces host, then Minikube. Each level has its own role. Some commands must target the Minikube agent specificallyâ€”especially when [4.4_max_heap_count_settings.png](configuring) host-level settings. Keep in mind, you're interacting with: the host, Codespaces, Minikube, container runners, SonarQube, and finally the scanner. Understanding this stack is key to troubleshooting and setup. In SDLC that is going to be your main challange understand the integration and how the code flows to pay the techical debt.

##### LO1-v3-LearnToDeployInEnvironment-Show-Do
SonarQube is a multi-tier systemâ€”UI, backend logic, and a database.  Youâ€™ll deploy it into a new environment using **Minikube**, a local Kubernetes cluster configured to run multiple (components)[4.5_rolloutstart.md] . Kubernetes helps you manage and observe all parts of your deployment.  Letâ€™s learn to deploy, inspect resources, and understand how everything fits together.Pod,Service,Deployment and Replica sets are internal component for the kubernetes to be able to run the processes. This course is not a kubernetes course. Still these are important concepts in the long run to learn in order to maintain the SonarQube in a containersed enterprise environment. 

##### LO4-V4:SETUP-ADMIN-PASSWORD-TELL-SHOW 
After launching SonarQube in Minikube, both the UI and database layers are active. The UI will prompt you to log in using the default credentials: admin/admin. Once logged in, you must reset the admin password. This new password is stored in the configuration database inside your Minikube environment. This step finalizes the initial setup and secures your SonarQube instance. As long as your Codespaces environment remains active, this password will persist. This process also confirms that the UI is correctly communicating with the backend and database, ensuring the system is ready to handle code scans and analysis tasks.


##### LO1-V4:SETUP-REPO-ENVIRONMENT-FIRST-PROJECT-TELL-SHOW
Set up the repository and environment to prepare for your first project. Our goal is to scan code automatically using SonarQube running in Minikube inside Codespaces. The code lives in the [4.8_GITHUB.PNG](GitHub repository) â€” thatâ€™s what weâ€™ll scan. The environment and the code are separate: we maintain the repo and the scanner seperately, not the same thing. Codespaces, which includes Minikube and SonarQube, will pull the repo and run a scan on every commit. â€” Watch how the repository in Github actions with our agent in the following steps [XXX](connects).

##### LO1-V4:GITHUB-SETUP-TELL-SHOW
The GitHub setup is critical to get all systems working in the background. Youâ€™ll need to authorize access and create both an App ID and a [SHOW](Client ID). These credentials are essential for integration and automationâ€”especially for connecting your repo to SonarQube scans. Take notes and store these values securely. Codespaces environments can be [DO]rebuilt or shut down at any time, so keeping track ensures you can recover and restart everything quickly.

**LO1-V4:GITHUB-APP-CONNECTOR-TELL-SHOW**  
For GitHub integration, weâ€™re using GitHub App connectors to allow apps to interact securely with your environment. Youâ€™ll need to [SHOW]grant access and manage the connection properly. As mentioned earlier, itâ€™s crucial to store your configuration detailsâ€”like App ID, Client ID, and secretsâ€”safely. Use systems like LastPass or a secured text file on a trusted cloud provider to hold your security notes. [DO]Connect the GitHub App to your environment to enable automated scans and background operations. This setup ensures consistent access and control, even if Codespaces is restarted or rebuilt.

**LO1-V4:GITHUB-KEY-GENERATION-TELL-SHOW**  
We are going to generate the keys needed to secure the GitHub environment. Your **Developer Settings** in GitHub will be the main area where this happens. In your GitHub application, youâ€™ll [SHOW]generate and manage these keys, including the private key and webhook secret. All of these should be placed into the same [DO]configuration file you use for the App ID and Client ID. Keeping everything together ensures the system can be easily restored or reused when rebuilding Codespaces. This step is essential for maintaining a secure and functional integration between GitHub and your SonarQube environment.

**LO1-V4:PRIVATE-KEY-PAM-FILE-TELL-SHOW**  
One of the key files youâ€™ll generate is the **.pem** (Privacy Enhanced Mail) file for your private key. This file is sensitive and should **never** be committed to source control. [DO]Use a `.gitignore` file to exclude it from your repo. The `.pem` file can be large and may create a cacheâ€”so youâ€™ll want to handle it carefully.  
Store this file securely in a configuration system like **LastPass**, **1Password**, or a trusted cloud storage service. [SHOW]Learn how to open and read this file using tools like `cat` or a text editor, so you can validate or migrate it when needed.

## **LO1-V4:PEM-FILE-HANDLING-TELL-SHOW**  
To manipulate `.pem` files, you can use **Notepad** or any text editor to view the content. [SHOW]Look for the markers:  
`-----BEGIN RSA PRIVATE KEY-----`  
`-----END RSA PRIVATE KEY-----`  
Make sure to **copy the entire content**, including the headers and footers. [DO]Paste it into a secure location like LastPass or your configuration vault. The private key works **together** with the public keyâ€”so you need to store **both**. If you only save the private key, remember the public key may already be on the server. Keeping both ensures you can rebuild or reauthenticate without issues.

#### **LO1-V4:GITHUB-WEBHOOK-CONFIG-TELL-SHOW** ğŸ”—  
Youâ€™ll set up a **webhook** so GitHub can notify your systems whenever changes occur in your repo. Your code lives in GitHubâ€”either as a public open-source repo or a private one. Itâ€™s a central and secure place to manage your code. [SHOW] SonarQube provides a **webhook URL** that tells the agent where to send scan events.  
[DO] One agent can send events to multiple URLs, so itâ€™s your job to configure it properly. ğŸ¯ Assign the correct webhook to your project so events flow to the right place, enabling automated scans and CI workflows. âš™ï¸

#### **LO1-V4:ENVIRONMENT-COMPONENTS-TELL-SHOW** ğŸ§©  
To understand the full setup, break down the key components: your **Dev environment** (the browser + GitHub Codespaces), where youâ€™ll enter and start building. Inside Codespaces, youâ€™ll run **Minikube** and install YAML templates to deploy **SonarQube**.  
[SHOW](4.9.7) SonarQube will connect to your **GitHub repo** using **webhooks**, and trigger **GitHub Actions** for CI events.  
[DO](4.9.7.B) All these componentsâ€”Dev tools, Minikube, SonarQube, GitHub, webhooks, and actionsâ€”must work together continuously. ğŸ” This integration helps track and resolve issues at every step, making sure your codebase is always being scanned and improved. âœ… By paying the technical debt

#### **LO1-V4:GITHUB-APP-PERMISSIONS-TELL-SHOW** ğŸ”  
When integrating your app with GitHub, youâ€™ll define **access levels and permissions** across your repos. With 100+ repos and 100+ permission types, itâ€™s important to manage access efficiently. [SHOW](4.9.8) In an enterprise environment, access is usually assigned **repo by repo**, specifying if the app can merge PRs, read code, or write to branches.  
[DO] For training or quick setup, you can assign permissions in **bulk**. If you're unsure, give access temporarilyâ€”then **delete the app** when you're done. âš ï¸ Always consider security. Granting only what's needed reduces risks and helps you manage trusted integrations responsibly. ğŸ›¡ï¸

#### **LO1-V4:SELECT-REPO-AND-DEPLOY-TELL-SHOW** ğŸ—‚ï¸  
Select your **GitHub repo** and [SHOW] **dismiss the top update message**â€”it can lead to unnecessary distractions or "yak shaving" ğŸƒ. Weâ€™re using a **YAML structure** to deploy SonarQube, which makes version updates simple and repeatable.  
[DO] The CI system will use the repo you choose on this screen to trigger scans. Iâ€™ve selected our existing **SonarQube repo**, and thatâ€™s perfectly fine. Once scanning starts, any issues will be shown in the results panel and you'll get notifications to address them. âœ… Keep things clean, focused, and version-controlled.

#### **LO1-V4:SETUP-SCANNING-AGENT-TELL-SHOW** ğŸ¤–  
To scan your project, youâ€™ll need an **agent**â€”in our case, that's **GitHub Actions**, which runs directly inside GitHub. [SHOW] Since your repo is already on GitHub, the agent can easily find and scan itâ€”location matters here. Keeping everything inside GitHub simplifies access and reduces setup friction.  
[DO] For this **proof of concept**, weâ€™re skipping complex security layers and network restrictions. ğŸ§ª The goal is to scan your code easily, test the setup, and allow controlled failures. In a **production setup**, youâ€™d add multiple security zones, but for now, speed and simplicity are key. ğŸš€

#### **LO1-V4:PROJECT-SCANNING-TRIGGERS-TELL-SHOW** ğŸ”„  
Set up your project for scanning, and make sure your **CI system works side-by-side** with SonarQube. [SHOW] Itâ€™s not enough to just link the projectâ€”you need to create **automated triggers**. These can fire on every commit, on a daily or weekly schedule, or based on specific conditions.  
[DO] These scans will automatically analyze your code and notify **stakeholders** via email, Slack, or Teams. ğŸ“¬ Once this system is in place, it becomes part of your workflow. You'll start receiving regular reports from the agent, making continuous analysis a seamless part of your development life. ğŸ› ï¸

#### **LO2-V4:START-GITHUB-ACTIONS-WITH-YAML-TELL-SHOW** âš™ï¸  
To get GitHub Actions running, start with a **simple YAML workflow**. [SHOW] YAML (Yet Another Markup Language) is the backbone of most modern platform configurationsâ€”essential for defining CI/CD pipelines, infrastructure, and deployment rules.  
[DO] I recommend using **GPT to help generate or review** your YAML files. In this repo, all prompts and examples are GPT-assisted. Ask it to explain or **add comments** if anything feels unclear. This makes your workflows not just functional, but understandable. YAML is your **config language for infra**, so mastering it will pay off across platforms. ğŸ§ ğŸ“

#### **LO2-V4:COMMIT-TIMING-AND-QUALITY-ANALYSIS-TELL-SHOW** â±ï¸  
Understanding **commit timing** is crucial when working with Git repositories. Since you're using **Codespaces**, Git is already installed, and you're working with a browser-based IDE. [SHOW] Each commit is like a **cell division in your system's DNA**â€”whenever you change code, it gets replicated.  
[DO] It's essential to **pay down technical debt** with each commit. SonarQube will automatically analyze each commit and flag any **quality issues**. ğŸš¨ The trigger for this analysis is vital: it ensures that as soon as a commit happens, potential problems are identified early, helping you maintain high-quality, clean code. ğŸ§‘â€ğŸ’»


#### **LO2-V4:HANDS-ON-SONARQUBE-DEPLOYMENT-TELL-SHOW** ğŸ› ï¸  
In this **hands-on experience**, you'll create your own **GitHub environment**. Start by creating a GitHub account and a new repository. You can either **fork** my repo or **start from scratch**. [SHOW] Ensure that you complete all sign-up steps to get your environment set up.  
[DO] The **free-tier Codespaces** should work fine for this project, but if you want to keep your system from shutting down, consider upgrading. Your main goal is to **deploy a SonarQube cluster** within a **Minikube** environment. Minikube is a small, local Kubernetes cluster that will let you see the **SonarQube UI** running directly within your setup. This step is crucial to see SonarQube in action and interact with the analysis process! ğŸš€

#### **L02-In-Video Question** ğŸ¥
What do you think about the environments we've set up for this section? Do you feel comfortable using **Codespaces** and a **browser-based approach**? Is your **internet connection stable** enough to handle this setup? Are you planning to use **Mac** or **Windows** for this project? Do you feel confident following the **AI-driven setup** process? Lastly, have you explored the **SonarQube environment**? Everything weâ€™ve covered should be replicable on your end. Remember to check the **GitHub repo** where Iâ€™ve recorded every step. You should be able to reverse engineer the setup by reviewing the repository. 
Please answer all of these questions to reflect on your progress! ğŸ˜Š

#### **LO1-V4:YAML-CONNECTS-SYSTEM-TELL-SHOW**  
YAML plays a crucial role in connecting various parts of the system. In the SonarQube ecosystem, you'll see the use of multiple layers of Linux environments. Initially, you're working within a **Linux inside another Linux** to trigger processes. Here's how it works:  
1. **Checkout the code**: The first step is to pull the repository code.  
2. **Scan the repository**: Once the code is checked out, the scan process begins.  
3. **Key components**: To run the scan, two essential pieces are required:
   - **Token**: For authentication.
   - **Host URL**: To connect to the scanning service.  
4. **GitHub Actions**: These actions are set to first check out the code and then trigger the scan with SonarQube.  
This setup allows the **GitHub Actions** to understand that after the code is checked out, it will automatically run the scan and execute the necessary build processes accordingly.

#### **LO1-V4:ENVIRONMENT-VARIABLES-TELL-SHOW**  
When working on remote systems, **environment variables** are your best friend ğŸ–¥ï¸. They are crucial in any systemâ€”Linux ğŸ§, DOS, or macOS ğŸ. To get the most out of your environment, **load these variables** ğŸ› ï¸. If you're using GitHub Codespaces, youâ€™ll directly interact with these environment variables.  
To familiarize yourself with them:  
- Use the **terminal** ğŸ–¥ï¸ (Mac Terminal, Windows PowerShell).
- Use **GPT** ğŸ’¬ to understand the concept of environment variables and how they function in your setup.  
These variables are key to configuring the system properly âš™ï¸. If you can't set them correctly, the system won't be able to run your jobs for SonarQube.

#### **LO1-V5:ENVIRONMENT-VARIABLES-POWER-AND-USAGE-TELL-SHOW** ğŸŒ
Working on remote systems? Environment variables will be your best friend. [SHOW] These variables are used across Windows (PowerShell), macOS (Terminal), and Linux systems to pass configuration values like tokens, URLs, and secret keys into your runtime environments. They are also essential in CI/CD systems like GitHub Codespaces or GitHub Actions.
[DO] Try setting them in your local terminal to get hands-on practice:
In PowerShell:
powershell
Copy code
$env:MY_VARIABLE = "my_value"
echo $env:MY_VARIABLE
In macOS/Linux:
bash
Copy code
export MY_VARIABLE="my_value"
echo $MY_VARIABLE
Use GPT to explain any part of this you donâ€™t fully getâ€”ask it â€œWhat is an environment variable?â€ or â€œWhy use these in CI/CD?â€ ğŸ§ ğŸ” Mastering this will help you securely configure systems without hardcoding values into your code.

#### LO1-V6:TRIGGER-SCAN-AFTER-COMMIT-TELL-SHOW ğŸ”
Every commit triggers a scan process via GitHub Actions. [SHOW] Youâ€™ll see this in your repoâ€™s Actions tabâ€”each workflow run shows live status like âœ… success or âŒ fail, helping you trace issues quickly.
[DO] Expect friendly fails at the beginning! Thatâ€™s normal. SonarQube checks your code for technical debt, and itâ€™ll highlight issues automatically. Your job is to identify the root cause and apply improvements. Donâ€™t rush to pass everything; instead, define a reasonable quality gateâ€”code should meet basic standards without blocking all progress. Learn to strike a balance between quality enforcement and dev speed. ğŸš¦ğŸ› ï¸

#### LO1-V8:UNDERSTAND-COSTS-OF-AGENTS-TELL-SHOW ğŸ’¸
When running GitHub Actions or using CodeSpaces, it's important to understand what youâ€™re actually paying for. [SHOW] In this setup, the agent (GitHub Actions) is serverless, meaning you donâ€™t own or run a full-time serverâ€”it spins up on demand, does the job, and shuts down. Thatâ€™s why the cost is low: around $4/month for V40s agents and associated CodeSpaces.
[DO] Think of it like renting a car ğŸš—â€”you only pay when you drive. Serverless infrastructure is cost-efficient when you donâ€™t need 24/7 uptime. Instead of paying to keep a host always on, GitHub gives you shared infra, which is perfect for CI/CD jobs that run for short bursts. Use this model wisely to optimize your spending while getting powerful compute on demand. ğŸ§®ğŸ“Š

#### **LO1-V9:ENHANCE-CODE-SHARING-WITH-IDES-TELL-SHOW** ğŸ§‘â€ğŸ’»ğŸ”—  
Working with GitHub commits is easier when using a **desktop IDE** like **Visual Studio** or **VS Code**. [SHOW] These tools offer powerful features and **extensions**â€”and you can even use them **inside GitHub CodeSpaces**. One essential extension is **"Copy GitHub URL"**, which lets you right-click any file or line and get a direct link to share with your team.
[DO] Whether in CodeSpaces or on your **local machine**, make sure to install helpful extensions that **sync across devices** using your Microsoft account. When SonarQube flags issues, youâ€™ll need to **share specific file locations** easily. Use these tools to collaborate faster, debug smarter, and level up your dev setup. ğŸš€ğŸ§©

#### **LO1-V10:SHARE-SONARQUBE-INSIGHTS-WITH-YOUR-TEAM-TELL-SHOW** ğŸ¤ğŸ”  
As mentioned earlier, the main goal of using **SonarQube** is to **pay down technical debt**. [SHOW] You're operating in an **open-source mindset**â€”this means actively **sharing URLs**, reviewing feedback, and collaborating with teammates to improve code quality.
[DO] Donâ€™t isolate yourselfâ€”**avoid working in silos**. Use features like **â€œCopy GitHub URLâ€** or **SonarQube report links** to initiate conversations. Drop those links into Slack, Teams, or pull request comments. Make it a habit to **discuss code issues openly**, and **learn from your teamâ€™s perspective**. SonarQube isnâ€™t just about finding problemsâ€”itâ€™s a **learning experience** that gets better the more you collaborate. ğŸŒ±ğŸ“

#### **LO1-V11:USE-URLS-MARKDOWNS-AND-INDEXES-TO-COMMUNICATE-CODE-TELL-SHOW** ğŸ”—ğŸ—‚ï¸  
When working in **GitHub Codespaces**, youâ€™ll notice that **sharing URLs**, **committing clearly**, and **naming resources** becomes a critical part of your workflow. [SHOW] This is a browser-based IDE, but the same concepts apply across environmentsâ€”**indexing your folders**, using meaningful names like `048-UI`, and **organizing with Markdown** all help make your system more readable.
[DO] Use GPT to help maintain structure and clarity. Maintain a personal index structure and be consistent. Markdown is your **visual communicator**â€”make sure your READMEs, documentation, and code comments are easy to follow. As you introduce concepts like **technical debt**, your job will also be to **explain it well to non-technical stakeholders**. Communicating is codingâ€”**index smart, document clear, and share responsibly**. ğŸ“šğŸ’¬

#### **LO1-V12:VISUALIZE-TECHNICAL-DEBT-WITH-EXTENSIONS-TELL-SHOW** ğŸ§©ğŸ“Š  
Using **extensions for SonarQube, YAML, and Markdown** takes your coding experience beyond textâ€”it becomes **a visual game** where managing **technical debt** feels structured and clear. [SHOW] With IDE plugins and GitHub integrations, youâ€™ll start to **see issues before they grow**, understand error highlights, and grasp complexity via visuals.
[DO] Install key extensions in **Codespaces or local VS Code**, including SonarQube support, Markdown preview, and YAML validators. These make it easier to **spot issues, explain problems, and collaborate**. Leverage **GPT to help comment, structure, and write your Markdown**, especially when documenting technical decisions. Your goal? **No more cryptic folders or hidden logic**. Every file should be understandableâ€”even if you come back to it months later. ğŸ› ï¸ğŸ“‚

#### **LO1-V13:SHOWCASE-SONARQUBE-IN-YOUR-CAREER-TELL-SHOW** ğŸ¯ğŸ’¼  
As an instructor or developer, **making your work visual and measurable boosts both credibility and career growth**. [SHOW] SonarQube isnâ€™t just a toolâ€”itâ€™s a **career asset**. Mentioning it in your **CV, LinkedIn, and GitHub projects** shows you care about clean code and scalable systems.
[DO] If you're using SonarQube in projectsâ€”especially in tools like your **Delivery Pilot**â€”**document it clearly**. Share your learnings, screenshots, and metrics. Mention how it helped you **reduce technical debt** and improve code quality. Add it as a skill on LinkedIn and explain your usage in project descriptions. Recruiters and teams value professionals who don't just write code, but improve its health and maintainability. ğŸ› ï¸ğŸš€

#### **LO1-V14:USE-SONARQUBE-AS-A-CREDIT-SCORE-TELL-SHOW** ğŸ“ŠğŸŒ  
In the future, your **technical debt score** will be just as important as your credit score. [SHOW] LinkedIn and other professional platforms are already asking for **GitHub URLs** on project listings, and **SonarQube** is key to demonstrating the **quality** of your code. It's no longer enough to show *just* your projectsâ€”you need to show **quality projects**. SonarQube helps you do that by tracking **technical debt** and offering insights on how to improve.
[DO] Treat your GitHub as your **digital portfolio**, and SonarQube as your **proof of quality**. By actively monitoring and improving your code quality, you'll signal to future employers or collaborators that youâ€™re serious about **software craftsmanship**. **Open-source contributions** are great, but **well-maintained, high-quality contributions** will make your profile stand out even more. **AI systems** and **recruiters** alike will take notice of your work. ğŸ“šğŸ’¼
And if you need guidance on this concept, there's a book called **"Show Your Work"** by Austin Kleon that perfectly aligns with this idea. Itâ€™s all about making your work visible and building your personal brand as a developer. ğŸŒŸ

#### **LO1-V15:INTEGRATE-SONARQUBE-INTO-YOUR-PROJECTS-TELL-SHOW** ğŸ“ˆğŸ”—  
When you work with **SonarQube**, you're not just improving code qualityâ€”you're also building a **digital history**. [SHOW] By tracking and committing your work on **GitHub** and integrating **SonarQube** into your projects, you create a clear trail of your progress. This helps you document every stage of your development process, from **initial integration** to resolving technical debt and improving code quality.
[DO] **Make sure to mention SonarQube in your projects**, both on GitHub and on platforms like **LinkedIn**. This not only showcases your technical ability but also highlights that youâ€™re committed to maintaining **enterprise-level quality**. It demonstrates to recruiters or collaborators that you're actively working on **scalable, high-quality solutions**â€”something that stands out in the competitive tech world. ğŸ”ğŸ’¡
Your **GitHub history** becomes your **proof** of expertise, and **SonarQube** acts as a tool that documents and improves that expertise. When you explain your projects, share how **SonarQube** helped you reach **quality gates**, address technical debt, and ensure sustainable development. **Let others see how youâ€™re growing**, and make your work visible to the broader tech community. ğŸŒğŸ‘©â€ğŸ’»ğŸ‘¨â€ğŸ’»

#### **LO1-V16:INTEGRATE-SONARQUBE-INTO-DAY-TO-DAY-DEVELOPMENT-TELL-SHOW** ğŸ”„ğŸ”  
As you work on your projects, youâ€™re not just codingâ€”youâ€™re **actively managing and improving** your **technical debt**. [SHOW] By integrating **SonarQube** into your **development lifecycle**, you ensure that every piece of code is consistently **scanned for quality**. The **GitHub history** becomes a **living record** of your work, capturing every update, every fix, and every improvement to your code.  
[DO] Treat **SonarQube** as part of your **daily development process**. **Clean up technical debt every day**, whether itâ€™s a small change or a major update. The more **SonarQube scans** you complete, the **higher the quality** of your software development lifecycle becomes. This consistent process shows **progress** in real time, proving your commitment to **quality code**.
Use **Markdowns**, **visual tools**, and **structured indexing** to make your **SonarQube results** clearer and more actionable. This not only makes it easier to understand the issues but also allows you to **track improvements over time**. The more you update your code with **SonarQubeâ€™s recommendations**, the stronger your **developer portfolio** becomes. Keep showing your work, keep improving, and stay ahead of technical debt! ğŸ“ˆğŸ’».

#### **LO1-V17:RECONNECT-AND-PAY-OFF-TECHNICAL-DEBT-TELL-SHOW** ğŸ”„ğŸ’³  
Think of **technical debt** as a **contract**â€”just like using a credit card for purchases, there's an ongoing responsibility to **pay off the debt**. [SHOW] If you stop paying, systems like **SonarQube**, **infrastructure**, and **code repositories** may shut down, and everything you've worked on will stop functioning. When you stop the system, you lose all progress unless you **reinitialize** the process.  
[DO] Always be ready to **pay off your technical debt** and **reconnect** the necessary components when they stop. This includes **reinitializing your setup**, such as the **mini Cube** or **GitHub Actions**, and following the steps outlined in the **underscore input** directory (located in the `second_minikube folder). Understand that each time you iterate, you need to **keep the debt paid off**â€”or else, your **development cycle** might grind to a halt.
Itâ€™s a simple but critical process: if you stop paying for the infrastructure, it **shuts down**. The key is knowing how to **reconnect** and keep everything running smoothly, ensuring that your **technical debt** doesnâ€™t prevent progress. ğŸš§âš™ï¸

#### **LO1-V18:SET-ENVIRONMENT-AND-RUBBER-DUCK-THE-PROCESS-TELL-SHOW** ğŸ§µğŸ§   
Open your terminal and navigate to the folder with `input.md`. [SHOW] This is where you'll set environment variables and run commands.  
[DO] Donâ€™t run everything blindlyâ€”**select and understand** each line. Use **Copilot** or **GPT** to comment and clarify. Structure your folders smartlyâ€”like `formulas/` for rules, errors, and references.  
This setup helps you "rubber duck" your processâ€”reviewing step by step makes debugging easier. Document as you go, and youâ€™ll build a self-healing workspace thatâ€™s ready for SonarQube and future iterations. ğŸ§°ğŸ’¬

#### **LO1-V19:RUBBER-DUCK-WITH-AI-AND-LOCK-STAGES-TELL-SHOW** ğŸ§ ğŸ§ª  
Lock your progress at **each stage**â€”P.O.C., prototype, production. [SHOW] This keeps your commits meaningful and traceable in complex systems like SonarQube.  
[DO] Rubber ducking means explaining your process, even to yourselfâ€”or in this case, the AI. Use **Copilot** or **GPT** to annotate changes and clarify decisions. Track evolving requirements and environment shifts between stages.  
Let your AI pair-program with you. The clearer your data and structure, the better the AI can help you manage complexity, debug issues, and ensure quality in every step. ğŸ¤ğŸ’»

#### **LO1-V20:SET-BREADCRUMBS-FOR-AI-NAVIGATION-TELL-SHOW** ğŸ§­ğŸ—‚ï¸  
Focus on **one document at a time**, but design your folder and file structure so the **AI can understand the full context**. [SHOW] In my `delivery_pilot` project, every task, prompt, and result is logged in the correct folderâ€”nothing is scattered.  
[DO] Create breadcrumb trails by saving prompt logs and outputs. This way, when something fails or needs debugging, you (or the AI) can retrace steps and find root causes. A clear structure + prompt history = **AI that truly helps**. Start small, stay consistent, and **log as you go**. ğŸ§±ğŸ¤–

#### **LO1-V21:STAY-NEUTRAL-AND-OPEN-TO-LEARN-TELL-SHOW** ğŸ§ ğŸŒ€  
Paying down tech debt frees your focusâ€”**less clutter, clearer goals**. [SHOW] Working in CodeSpaces? Expect hiccups, but donâ€™t get attached to a fixed setup. Stay flexible, restart when needed, and use GPT to help you learn.
[DO] Static analysis like SonarQube runs deepâ€”multiple rules, interwoven checks. Youâ€™ll need curiosity to understand how everything fits together. Drop blockers like â€œI wonâ€™t touch Docker.â€ That mindset stalls growth. Embrace the unknown, and **learning gets easier**. ğŸŒ±ğŸ§©

#### **LO1-V22:RECREATE-INFRASTRUCTURE-AS-YOU-LEARN ğŸ”âš™ï¸**  
Fixing systems *is* learning. [SHOW] When using GitHub Codespaces, expect them to expire if left idleâ€”Microsoft wonâ€™t cover infinite compute. Your infra setup (scripts, Kubernetes configs) will vanish unless you stay active.
[DO] Accept this impermanence. Practice recreating from `input.md` and document your process. The goal isn't one-time setupâ€”it's mastering rebuilds. Let GPT guide your repetition. Life interrupts, and thatâ€™s okay. Donâ€™t rush. Understand the system architecture and iterate calmly. The more you rebuild, the more you own your stack. ğŸ› ï¸ğŸ§˜â€â™€ï¸

#### **LO1-V23:UPDATE-SCRIPTS-BRAVELY ğŸ”„ğŸ“œ**  
Scripts are not staticâ€”*everything evolves.* [SHOW] GitHub Actions, Codespaces, and Kubernetes versions shift. Your configs must adapt too.
[DO] Go to your `scripts/` folder often. When things break, *donâ€™t panic*â€”edit the scripts, reconfigure, and re-run. The desired state is never guaranteed, itâ€™s *maintained*. Build the habit of refining your scripts instead of fearing failure. Courage to tweak and test is key. Every update is a chance to learn. ğŸ§ ğŸ’ª

#### **LO1-V24:RECONFIGURE-SECRETS & ASK GPT ğŸ”ğŸ¤–**  
Secrets like DB passwords are **not persistent**â€”they vanish with each reset. You must **redefine them** manually or through automation every time.
[DO] Revisit your configuration scripts. Identify connection points (e.g., DB URIs, tokens). Talk to GPT clearly:  
ğŸ—£ï¸ _"Search my codebase. What config am I missing to bring SonarQube back up?"_  
Use AI like a team memberâ€”debug with it, ask it to validate each step, and help you fill the gaps. Thatâ€™s how you stay in control when infra resets.

#### **LO1-V25: PODS, SERVICES, DEPLOYMENTS, REPLICAS ğŸš€**  
In Kubernetes:
- **Pods** = The processes running your applications. Think of them as the execution units.
- **Services** = Defines how these pods communicate within the cluster, either through a **ClusterIP** or **NodePort**.
- **Deployments** = Configuration that defines how your app is **deployed**, how it should scale, and the number of replicas.
- **ReplicaSets** = Ensures your specified number of pods (replicas) are always running. A **higher replica count** means **more memory usage**.  
In your **Minikube**, use **one replica** for simplicity and resource-saving. More replicas mean more resources, so be mindful when scaling.

#### **LO1-V26: PORTSAND RUNNINGSYSTEMğŸš€
When the system is up and running, hereâ€™s what youâ€™ll see:
1. **Pods** are the active processes that are running the application.
2. **Services** will be mapped to **ports**, exposing those services. For instance, youâ€™ll see **port 9000** being used, where the service is available.
3. **Port Forwarding** will direct traffic from port 9000 to the corresponding pod, allowing you to interact with the UI.
4. The **ReplicaSet** will ensure that your **deployment** is properly scaled, using one of the pods to run the process.
The **UI** will be accessible through the port forwarding configuration, visible and accessible via the port mapping (9000).

#### **LO1-V23:DIAGNOSE-AND-LEARN-FROM-ERRORS ğŸ§ ğŸ’¡**  
Errors *are* learning opportunities. [SHOW] In Kubernetes, unexpected errors like "unhandled error" will occur as systems initialize. These failures are clues, and understanding how to diagnose them is critical.  
[DO] Use the AI to help you break down errors, such as memory issues (e.g., adjusting the `VM Max Heap Count`). As you debug, gain familiarity with system variables, kernel settings, and Kubernetes configurations. These hurdles are your "gold mines"â€”they guide you toward better solutions. Embrace them as a tool for growth. Learn, iterate, and perfect your stack. ğŸ’»ğŸ”§

#### **LO1-V24:MANUAL-TO-AUTOMATED-DEBT-PAYMENT ğŸ”„ğŸ’»**  
Manual fixes *lead* to automation. [SHOW] Start by managing technical debt manuallyâ€”before SonarQube suggests improvements, take the time to manually identify and resolve issues in your system. This is an essential step to truly understanding the problems at hand.  
[DO] Document each manual fix thoroughly. As you become comfortable, integrate SonarQube to automate debt management. Then, set up a digital dashboard to track your progress. This approach ensures youâ€™re learning the process, not just relying on the tool. Pay down debt both manually and automatically, and see your system improve with each step. ğŸ“ŠğŸ’ª

#### **LO1-V25:YAK-SHAVING-AND-DEBT-PAYMENT ğŸ› ï¸ğŸ”§**  
Tech debt *requires* sacrifice. [SHOW] It's easy to wonder, â€œWhy am I learning all these concepts when my goal is just to use SonarQube?â€ The answer is yak shaving. Sometimes, solving a problem means going out of your way to clear obstacles. This *manual* debt payment lays the foundation for a smoother system.  
[DO] Embrace the process. Understand that paying down technical debt manually is crucial. By learning this, youâ€™re preparing your system to scale and improve in the long run. Get comfortable with manual fixes, and donâ€™t shy away from the extra workâ€”itâ€™s the path to better infrastructure. ğŸ§¹ğŸ’¡

#### **LO1-V26:MANUAL-TECH-DEBT-PAYMENT-STRATEGY ğŸ’»ğŸ“š**  
Manual tech debt *demands* precision. [SHOW] To pay it, start by creating a **`semblance`** folder using a markdown structure. In it, document your strategies, such as the YAML configurations and prompts.  
[DO] For each error, write down your troubleshooting steps and solutions. Keep iterating and adding the AIâ€™s responses along with the output until the issue is resolved. Regularly commit your changes and share them in an open-source manner for peer feedback. This is the process of manual tech debt paymentâ€”stay disciplined and refine the system step-by-step until youâ€™re ready to turn it on. ğŸ“œğŸ”§

#### **LO1-V27:USING-MULTIPLE-AI-ENGINES-FOR-TECH-DEBT-PAYMENT ğŸ¤–ğŸ”„**  
Paying technical debt *manually* involves leveraging multiple AI engines. [SHOW] Your primary choice is **CoPilot** on GitHub Codespaces, but when context grows, expand to other models like **Croc** for handling larger inputs and more complex error messages.  
[DO] As you solve issues, document all solutions, append the AI-generated responses at the bottom, and commit changes to version control. By using a mix of AI platforms, you enrich the troubleshooting process and improve static analysis within SonarQube. Always address problems manually before automating solutions with SonarQube. This iterative approach ensures precision and deeper understanding. âš™ï¸ğŸ’¡

#### **LO1-V28:FOLLOW-THE-STRUCTURE-TO-FIND-ANSWERS ğŸ“ğŸ§­**  
Your core documentation lives in Markdownâ€”structured with `#` headings and iterative updates. [SHOW] When a pod fails, you **log the pod ID**, append context, and refeed it into GPT for debugging.  
[DO] Stick to the folder logic:  
- `semblance/`: system state & errors  
- `formulas/`: GPT prompts  
- `ui/`: screenshots & frontend views  
- `real/`: OKRs  
Before asking questions, **read commit histories**â€”they're stories in disguise. This discipline helps you respect the past effort and guide your debugging with clarity. Everything has a place; every folder helps you navigate the chaos. ğŸ“˜ğŸ’¾

#### **LO1-V29:EMBRACE-K8S-WITH-AI-FIRST-MINDSET â˜ï¸ğŸ¤–**  
Namespace grouping in Kubernetes is essentialâ€”especially when managing an AI-first SonarQube deployment. [SHOW] All your YAML, pod configurations, and executions are AI-generated.  
[DO] Treat `kubectl` as your lens: inspect pods, track failures, and feed issues into GPT. Learn to ask the right questionsâ€”**GPT is your DevOps pair**. SonarQube instances from 2020s onward often live in Kubernetes clusters, so mastering this environment is non-negotiable. Start small, debug fearlessly, and leverage AI to build confidence in navigating and fixing K8s systems. ğŸ§ ğŸ”§

#### **LO1-V30:SMART-AI-STACK-SELECTION ğŸ¤¹â€â™‚ï¸ğŸ§ **  
Not all AI engines are freeâ€”**use them strategically**. [SHOW] Your default coding assistant might be GitHub Copilot (tight Codespaces integration). But when your prompts grow or tasks get complex:  
- Use **Grok** for long-context analysis.  
- Switch to **Claude** for structured reasoning and complex YAML/log debugging.  
[DO] Treat your AI tools like a toolboxâ€”**swap based on the problem**. Monitor quotas, understand each modelâ€™s strength, and rotate wisely. This agility turns you into an AI-native developer who can balance budget, capability, and context depth. ğŸ§°ğŸ’¡

#### **LO1-V31:INTUITION-IS-YOUR-SUPERPOWER ğŸ§­âœ¨**  
Your intuition *rocks*â€”trust it. [SHOW] In this M-shaped world (multi-domain, multi-tool), AI gives suggestionsâ€”but **you** connect the dots. While paying off tech debt manually, enjoy the craft. This is where your **intuition trains reliability**.  
[DO] When AI responds, pauseâ€”**sense-check** it. Use what *feels right* to explore deeper. When systems fail (and they will), itâ€™s human insight that rebuilds trust. Learn the rhythms, enjoy the mess, and remember: **manual mastery builds mental resilience**. Reliability isnâ€™t magicâ€”itâ€™s born from your thoughtful, repeated actions. ğŸ› ï¸ğŸ§ â¤ï¸â€ğŸ”¥

#### **LO1-V32:DEPENDENCY-AWARE-MANUAL-DEBT-PAYMENT â›“ï¸ğŸ““**  
We all have dependencies. [SHOW] In this case, GitHub Codespaces and Minikube are your *infrastructure lifelines*â€”but theyâ€™re fragile. Codespaces expire. Clusters break. And with that, your setup disappears.
[DO] Thatâ€™s why you **document and rebuild**. The *manual debt payment system* means: **you become the SonarQube**. You track issues. You write logs. You notify yourself. This isnâ€™t just DevOpsâ€”itâ€™s **self-reliance** engineering.
Every folder in your delivery pilot matters. Every error you document is a breadcrumb back to stability. Youâ€™re not automating yet. Youâ€™re earning your understanding. **Rebuilding is your rite of passage.** ğŸ§±ğŸ§â€â™‚ï¸ğŸ“’

#### **LO1-V33:VERIFY-WITH-AIâ€“RUBBERDUCK-EVERYTHING ğŸ¦†ğŸ¤–**  
Always **verify with AI**. [SHOW] Everything you touchâ€”from Kubernetes configs to machine specsâ€”deserves a question. Not just because AI knows, but because **you learn by asking**.
[DO] This is called the **Rubberduck Process**:  
You go from **UNKNOWN â†’ KNOWN** by saying things out loud (or in prompts).  
Example:  
> *"I want to set up SonarQube in Minikube using Codespaces. Which machine type should I select?"*  
That's not weakness. Thatâ€™s *clarity creation*. You're making fog into form. And the better your questions, the sharper your answers. Use CoPilot, Claude, GPT, Grokâ€”whatever engine you need.  
ğŸ” *Ask. Verify. Re-ask. Learn.*  
ğŸ§  The conversation *is* the build.


#### **LO1-V34:SONARQUBE-IN-MINIKUBE-ON-CODESPACES ğŸ–¥ï¸ğŸš€**  
Weâ€™re spinning up SonarQube inside Minikube on Codespaces. This is a memory-intensive N-tier system, so make sure your machine starts with 4 CPUs and 8GB RAM. Run the starter script, watch the pods, and document everything â€” unknowns, AI questions, YAML tweaks.
Use Copilot for inline help and escalate to Grok or Claude for longer outputs. Every error is a gold mine â€” follow the Rubber Duck method: ask smart questions and move from UNKNOWN to KNOWN. Youâ€™re not just coding, youâ€™re learning to debug with AI. Letâ€™s build!

#### **LO1-V34:MONITORING-VIRTUAL-MACHINE-RESOURCES ğŸ–¥ï¸ğŸ”**  
To understand whatâ€™s happening in your virtual machine as a Linux cell, use the `top` command. This shows you running processes, including SonarQube-related and DNS processes, along with memory and CPU usage. **Unknown** is a state where more space equals better performance, but **known** means you've allocated RAM and CPU resources for both the host and Minikube. Ensure thereâ€™s enough space for both to operate effectively. Running SonarQube requires significant memory and CPU to load the system, run scans, and generate results. **This is a memory and CPU-intensive process** that demands careful resource management.

#### **LO1-V35:MONITORING-SYSTEM-PROCESSES-AND-CONTAINERS ğŸ› ï¸ğŸ“Š**  
After spinning up your system on HWAP, check the containers. You'll see some are still creating, while others are running. The critical containers to monitor are **SonarQube** and **SonarQube Database**. The **SonarQube Database** stores your records, which you may need to back up in an enterprise environment. The **SonarQube UI** and business layer handle scans. The **Unknown** state refers to the container's running state, which you should check regularly. Think of it like checking the Task Manager on Windows or the Terminal on macOS. Use `kubectl get all -n sonarqube` to check all objects in the SonarQube namespace. Always monitor these to stay aware of your systemâ€™s health.

#### **LO1-V36:MONITORING-SYSTEM-INITIALIZATION-AND-DEBUGGING ğŸ”„âš™ï¸**  
Monitoring SonarQubeâ€™s system initialization requires you to understand both its success and failure states. [SHOW] After launching, check the `localhost:9000` URL in GitHub.dev to confirm that SonarQube is up and running. The system will initialize, but donâ€™t be surprised if it failsâ€”common issues include database or load balancer problems.  
[DO] Document every error or failure you encounter and update your Git project regularly. Each problem provides valuable learning, and capturing the UI state when it loads successfully helps track progress. Debugging and re-running steps ensure a deeper understanding of how to keep the system operational.

#### **LO1-V37:VERIFYING-SONARQUBE-PORT-FORWARDING-AND-CONNECTIONS ğŸŒğŸ”**  
Once SonarQube is running, youâ€™ll observe port forwarding activity in the terminal, specifically handling connections to port `9000` for each incoming request. [SHOW] This indicates that the system is up and running.  
[DO] The unknown here is what might happen behind the scenesâ€”whether the system will function smoothly or encounter issues. However, youâ€™ll know itâ€™s operational when you see active requests in the port forwarding logs. Even though you canâ€™t see everything in the background, tracking these logs ensures you understand the traffic flow and the connection status in SonarQube.

#### **LO1-V38:AVOIDING-LOST-CONFIGURATION-AND-BACKING-UP-SONARQUBE-SETUP ğŸ› ï¸ğŸ’¾**  
Losing configuration is one of the worst setbacks you can face. [SHOW] When GitHub Codespaces gets destroyed, all the configurations youâ€™ve set upâ€”especially how SonarQube connects to the agent and GitHubâ€”will be lost. Your Minikube runner, which connects to GitHub via the SonarQube setup, will be severed.  
[DO] To prevent this, use tools like **LastPass** and **Obsidian** for secure, easy-to-access documentation. Keep a Markdown file with your configuration details and update it regularly. This manual process of documenting your setup becomes your technical debtâ€”ensure you follow your markdown to recreate the system whenever needed. By doing this, you can confidently restore or reconfigure the system without losing crucial setup details.

#### **LO1-V39:CONFIGURATION-DOCUMENTATION-IN-OBSIDIAN-AND-LASTPASS ğŸ“šğŸ”**  
To prevent losing track of your configurations, use **Obsidian** as your second brain and **LastPass** for secure storage. [SHOW] Store all your configuration details in Obsidian, linking and tagging each entry for easy retrieval. If you need extra security, keep critical information in **LastPass** or a secure text file. For open-source projects, make sure sensitive data is **.gitignored** and not exposed in repositories.  
[DO] Organize your notes by tagging and linking them for easier access, ensuring you can quickly locate the configuration details needed to rebuild the system. Remember, if you have a large knowledge base (like 1.1 million words in Obsidian), the key to avoiding overwhelm is well-structured links and tags. Documenting and linking configurations will reduce your technical debt and make it easier to recreate your systems in case of failure.

#### **LO1-V40: CONFIGURATION MANAGEMENT AND MAINTAINING RELIABILITY ğŸ› ï¸ğŸ”„**  
Managing configurations efficiently is key to reducing errors. [SHOW] I create a template for my configuration, with placeholders like "xxx", that I update regularly. Each time itâ€™s updated, I store it in my second brain â€” whether itâ€™s LastPass, Obsidian, or another secure location. By doing this, I minimize errors and maintain a reliable system.  
[DO] Start from the *Unknown* and focus on what could fail next. While you have your *Known* â€” the complex multi-stage configuration â€” always be aware that unexpected changes can happen, and new issues may arise. Systems with many moving parts, like this one, require constant attention to whatâ€™s beyond your immediate control, and the key is to stay proactive in solving what may fail next. By tracking these changes and knowing where to find your updated configurations, you ensure youâ€™re always one step ahead in keeping your system stable.

#### **LO1-V42: EXTERNAL ACCESS AND SYSTEM VISIBILITY IN MULTI-COMPONENT SETUPS ğŸŒğŸ”**  
External access to your systems, like Obsidian on Codespaces, plays a crucial role in enabling integration with platforms like GitHub Actions. [SHOW] You need to manage the visibility of your components â€” deciding which ports are public or private â€” to ensure smooth communication with these external systems. Webhooks are vital for sending events back to you, so you can monitor your progress.  
[DO] Document all the URLs, events, and errors in a structured folder like "semblance". When things donâ€™t work, donâ€™t ignore them; this is your *Unknown*. As part of your *Known*, you should constantly assess your multi-stage configuration and track any issues. Use AI to read through your logs and help diagnose where you got stuck during the SonarQube setup or operations. Regularly update your documentation, index it, and make sure you can trace your history easily, ensuring that each step of your debugging journey is well-documented.

#### **LO1-V43: HANDLING DYNAMIC URLS AND CALLBACK CONFIGURATION ğŸŒğŸ”„**  
One common mistake when setting up SonarQube on Codespaces is missing the correct port number. [SHOW] In the beginning, I forgot to include the port in my callback URL, which caused issues when trying to send events back to SonarQube. The dynamic nature of the Codespaces load-balanced URL means it changes each time you create the service, so the callback URL needs to be publicly accessible to ensure webhooks can communicate with your SonarQube instance.  
[DO] Always make sure to update these URLs in your integration systems when you notice that the load-balanced URLs have changed. Your *Unknown* is what might fail, like missing port numbers or broken callbacks, but your *Known* is the process you go through: recording and revising each failure as it happens. Keep track of the history of changes and errors in your documentation. This enables you to identify what went wrong, how to fix it, and how to proceed confidently in the future.

#### **LO1-V44: CONFIGURING SONARQUBE ENVIRONMENT VARIABLES ğŸ› ï¸ğŸ”**  
When integrating SonarQube with GitHub, setting the correct environment variables is crucial.
[SHOW] Pay close attention to the **Sonar Token** and **Sonar Host URL** â€” these two environment variables must be correctly configured in GitHub Secrets for the integration to work properly. The **Sonar Token** is your authentication key, and the **Sonar Host URL** points to where your SonarQube instance is running.  
[DO] As you work through these configurations, remember that your *Unknown* is which environment variable might cause issues, but your *Known* is the systematic recording of each configuration change. Store the values in your systemâ€™s config file and document each step in your markdowns. This helps ensure that if anything goes wrong, you can refer back to your detailed logs and correct the problem based on your documented history.

#### **LO1-V45: HANDLING CODESPACES RESET AND ENVIRONMENT VARIABLE MANAGEMENT ğŸ”„ğŸ”§**  
In Codespaces, losing data or restarting can require resetting key environment variables.
[SHOW] When you lose access to your Codespace, youâ€™ll need to recreate the environment variables, such as the **Sonar Token** and **Sonar Host URL**, because these URLs change every time the Codespace is reset. This process gives you the opportunity to practice updating and managing GitHub Secrets and environment variables.  
[DO] Your *Unknown* here is which environment variable may fail, but your *Known* is the process of carefully updating these values when Codespace is reset or lost. Always document these changes, as this will help ensure your GitHub Actions integrate properly, and you'll be able to track the movement of components like SonarQube through every reset.

#### **LO1-V46: MANAGING SONARQUBE PROJECT KEY ROTATION ğŸ”‘ğŸ”„**  
In Codespaces, each new SonarQube setup creates a fresh database, resulting in a **new project key**. [SHOW] The project key will change every time you initialize a new SonarQube instance, which can be challenging to predict. The key is a global unique identifier for your SonarQube project, and youâ€™ll need to be ready for it to rotate each time you set up.  
[DO] Your *Unknown* here is the unpredictable nature of the project key change, but your *Known* is that this key will change with every new SonarQube project. Save the updated key in the `sonar-project.properties` file at the root of your project so SonarQube knows which configuration to apply. By tracking and documenting this change, you ensure smooth integration and avoid disruption in your workflow.

#### **LO1-V47: SONARQUBE STATIC ANALYSIS AND THE HUMAN TOUCH ğŸ§ ğŸ’»**  
Once youâ€™ve set the variables and integrated your SonarQube system, it will monitor your project and perform **static code analysis** to identify **technical debt** in your codebase. 
[SHOW] SonarQube will scan the project and provide feedback on areas that need improvement, offering a thorough report on issues like bugs, vulnerabilities, and code smells.  
[DO] The *Unknown* here is which parts of your project will need the most attention during each scan, as it may vary with every new build or feature added. Your *Known* is that as long as the configuration keys are correctly set and the system is running, SonarQube will be ready to perform its scans and notify you of any issues. Remember, while AI plays a crucial role in identifying technical debt, **human intuition** is essential for interpreting results and making change approvals.

#### **LO1-V48: SONARQUBE TRIGGERS AND NOTIFICATIONS ğŸ“ˆğŸ””**  
The key to triggering SonarQube scans is based on **commit saves**. [SHOW] In enterprise environments, the frequency of scans can vary, with some companies opting for scans after every commit, others after every hour, or for certain branches. These decisions depend on the number of commits, the resources available, and the business rules they have in place.  
[DO] The *Unknown* is when exactly the scan will be triggered, as it can vary based on factors such as the frequency of commits and the team size. Your *Known* is that SonarQube scans rely on an agent running within the **GitHub actions** pipeline, and youâ€™ll receive success reports with notifications. These reports will guide you on what changes need to be made to improve your codebase, making it essential to stay up-to-date with notifications to understand where changes are required.

#### **LO1-V49: MONITORING GITHUB ACTIONS AGENT ğŸ–¥ï¸ğŸ”**  
To monitor your **GitHub actions** agent, 
[SHOW] navigate to your **GitHub repository**, then click on the **Actions** tab. Here, youâ€™ll see the status of various workflows. If the status is **yellow**, the action is running; if itâ€™s **red**, the action has failed; and if itâ€™s **green**, the action has passed.  
[DO] The *Unknown* is which actions will fail, and the *Known* is that the color-coded status helps you quickly identify whether an action is running successfully. When dealing with many repositories and workflows (over 100+), this can become a complex matrix of actions running in the background. Focus on the notifications and investigate the failures to understand why they occur. This is part of the **yak shaving** process, where you delve deep into the components to ensure everything is functioning smoothly.

#### **LO1-V50: UNDERSTANDING THE FIRST SUCCESS AND MONITORING CODE QUALITY ğŸŸ¢ğŸ“Š**  
The first moment of success is when you see your **SonarQube project pass** and gain insights into your project's coverage and duplications. [SHOW] A **green** status indicates your project is performing well, and youâ€™ll be able to see the lines of code covered, duplicated code, bugs, vulnerabilities, and other issues detected.  
[DO] The *Unknown* is when your project will successfully pass, as there may be fluctuating factors. The *Known* is that once SonarQube runs, it will show static code coverage, and you can drill down into issues. Address the **bugs, vulnerabilities, code smells**, and **duplicated code**â€”this is your technical debt to pay off. Be mindful that **paying off technical debt** requires time and effort, and there's always a cost in terms of resources and focus to ensure long-term code health.

#### **LO1-V51: TRACKING TEST COVERAGE AND IMPROVING CODE QUALITY ğŸ§ªğŸ”**  
When reviewing reports, **test coverage** is crucial to assess if your code is adequately tested. [SHOW] SonarQube will highlight **covered lines** and test failures, but remember that setting up tests for all projects may not always be feasible.  
[DO] The *Unknown* is understanding what parts of your code might fail in testing, especially in complex environments with multiple teams and projects. The *Known* is that **static analysis** tools like SonarQube help identify coverage gaps, errors, and failures. By recognizing areas for improvement, you can enhance your **test coverage** to ensure your codebase becomes **robust** and **anti-fragile**, ultimately making it more **releaseable** and trustworthy.

#### **LO1-V52: CREATING AND HANDLING ARTIFICIAL FAILURES FOR TESTING ğŸ”§âš ï¸**  
You can create intentional **failing statuses** to test your system's resilience. [SHOW] Use AI to simulate a **division by zero error**, which is one of the simplest errors to check. For instance, using `print(a / b)` where `b` is 0 will trigger a **divide by zero** error.  
[DO] The *Unknown* is whether this artificial failure will occur as expected, so understanding how these errors impact your system is critical. By mastering error handling and failure simulation, you can strengthen your test coverage and ensure the system behaves predictably, even in edge cases. This process will help you **validate error-handling workflows** and **improve system reliability**.

#### **LO1-V53: SCALING INTENTIONAL ERROR CREATION FOR RELIABILITY TESTING âš¡ğŸ’»**  
Once your package is optimized, you can introduce **intentional errors** (like division by zero) anywhere in your codebase. The **Unknown** here is how many test cases (or failure scenarios) you need to account for. **SonarQube** gets updated, and there are **many edge cases** beyond just dividing by zero that could cause issues.  
[DO] You can scale this testing by simulating multiple types of failures across different parts of your system. The goal is to test **SonarQube**'s ability to handle various errors. By automating these tests and ensuring that **SonarQube** properly identifies these failures, you validate the **reliability** of your system.  
Test your errors systematically and regularly to ensure the system remains **stable and resilient** even as the code evolves and new configurations are introduced.